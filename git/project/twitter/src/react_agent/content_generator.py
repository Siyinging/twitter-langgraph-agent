#!/usr/bin/env python3
"""æ™ºèƒ½å†…å®¹ç”Ÿæˆå™¨ - ä¸ºæ¯æ—¥Twitterå‘å¸ƒç”Ÿæˆå„ç±»ç§‘æŠ€å†…å®¹

åŒ…å«ï¼š
- ä»Šæ—¥ç§‘æŠ€å¤´æ¡ç”Ÿæˆ
- å¯æŒç»­AIçº¿ç¨‹å†…å®¹ç”Ÿæˆ
- ä¼˜è´¨è½¬å‘å†…å®¹å‘ç°
- æœ¬å‘¨è¶‹åŠ¿å›é¡¾ç”Ÿæˆ
"""

import asyncio
import json
import logging
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path

from langchain_tavily import TavilySearch
from react_agent.tools import _get_all_mcp_tools, search

logger = logging.getLogger(__name__)


class TechContentGenerator:
    """ç§‘æŠ€å†…å®¹ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.data_dir = Path("data")
        self.data_dir.mkdir(exist_ok=True)
        
        # å¯æŒç»­AIè¯é¢˜åº“
        self.sustainable_ai_topics = [
            {
                "theme": "ç»¿è‰²è®¡ç®—",
                "content": [
                    "ğŸŒ± å¯æŒç»­AIå‘å±•å·²æˆä¸ºç§‘æŠ€ç•Œçš„é‡è¦è®®é¢˜ã€‚éšç€AIæ¨¡å‹è¶Šæ¥è¶Šåºå¤§ï¼Œå…¶èƒ½è€—é—®é¢˜ä¹Ÿæ—¥ç›Šå‡¸æ˜¾ã€‚",
                    "ğŸ’¡ ä¼ ç»Ÿå¤§å‹æ¨¡å‹è®­ç»ƒæ¶ˆè€—å·¨å¤§ç”µåŠ›ï¼Œç›¸å½“äºæ•°ç™¾ä¸ªå®¶åº­ä¸€å¹´çš„ç”¨ç”µé‡ã€‚æˆ‘ä»¬éœ€è¦æ›´é«˜æ•ˆçš„ç®—æ³•ã€‚",
                    "ğŸ”§ æ–°å…´çš„ç¥ç»ç½‘ç»œå‰ªæã€çŸ¥è¯†è’¸é¦æŠ€æœ¯æ­£åœ¨å¸®åŠ©å‡å°‘æ¨¡å‹å‚æ•°ï¼Œåœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶å¤§å¹…é™ä½èƒ½è€—ã€‚",
                    "ğŸ“Š ç ”ç©¶æ˜¾ç¤ºï¼Œä¼˜åŒ–åçš„AIæ¨¡å‹èƒ½æ•ˆå¯æå‡70%ï¼Œè€Œå‡†ç¡®ç‡ä»…ä¸‹é™2%ã€‚è¿™æ˜¯å€¼å¾—çš„æƒè¡¡ã€‚",
                    "ğŸš€ æœªæ¥AIå‘å±•æ–¹å‘ï¼šæ›´èªæ˜è€Œéæ›´å¤§ã€‚è®©æˆ‘ä»¬å…±åŒæ¨åŠ¨ç»¿è‰²AIæŠ€æœ¯ï¼Œä¸ºåœ°çƒè´¡çŒ®ä¸€ä»½åŠ›é‡ï¼ #å¯æŒç»­AI #ç»¿è‰²è®¡ç®—"
                ]
            },
            {
                "theme": "è¾¹ç¼˜AI",
                "content": [
                    "ğŸŒ± è¾¹ç¼˜AIæ­£åœ¨é‡æ–°å®šä¹‰å¯æŒç»­è®¡ç®—ã€‚å°†æ™ºèƒ½æ¨å‘è®¾å¤‡ç«¯ï¼Œå‡å°‘äº‘ç«¯ä¾èµ–ï¼Œæ˜¯ç»¿è‰²AIçš„å…³é”®æ–¹å‘ã€‚",
                    "ğŸ’¡ åœ¨æ‰‹æœºã€IoTè®¾å¤‡ä¸Šè¿è¡ŒAIæ¨¡å‹ï¼Œå¯ä»¥å‡å°‘æ•°æ®ä¼ è¾“ï¼Œé™ä½å»¶è¿Ÿï¼ŒåŒæ—¶å¤§å¹…èŠ‚çœäº‘è®¡ç®—èµ„æºã€‚",
                    "ğŸ”§ æ–°çš„é‡åŒ–æŠ€æœ¯å’Œä¸“ç”¨èŠ¯ç‰‡è®©å¤æ‚AIæ¨¡å‹èƒ½åœ¨åŠŸè€—ä»…å‡ ç“¦çš„è®¾å¤‡ä¸Šé«˜æ•ˆè¿è¡Œã€‚",
                    "ğŸ“Š é¢„è®¡åˆ°2026å¹´ï¼Œ70%çš„AIæ¨ç†å°†åœ¨è¾¹ç¼˜è®¾å¤‡å®Œæˆï¼Œäº‘ç«¯èƒ½è€—å°†å‡å°‘40%ã€‚",
                    "ğŸš€ åˆ†å¸ƒå¼æ™ºèƒ½æ—¶ä»£æ¥ä¸´ï¼æ¯ä¸ªè®¾å¤‡éƒ½æ˜¯ä¸€ä¸ªå°å‹AIå¼•æ“ï¼Œå…±åŒæ„å»ºæ›´å¯æŒç»­çš„æ™ºèƒ½ç”Ÿæ€ã€‚ #è¾¹ç¼˜AI #ç‰©è”ç½‘"
                ]
            },
            {
                "theme": "AIä¼¦ç†",
                "content": [
                    "ğŸŒ± å¯æŒç»­AIä¸ä»…å…³ä¹ç¯å¢ƒï¼Œæ›´å…³ä¹è´Ÿè´£ä»»çš„æŠ€æœ¯å‘å±•ã€‚æˆ‘ä»¬éœ€è¦å¹³è¡¡åˆ›æ–°ä¸è´£ä»»ã€‚",
                    "ğŸ’¡ AIåè§ã€éšç§ä¿æŠ¤ã€ç®—æ³•é€æ˜åº¦ç­‰é—®é¢˜ï¼Œéƒ½æ˜¯å¯æŒç»­å‘å±•å¿…é¡»è€ƒè™‘çš„ç»´åº¦ã€‚",
                    "ğŸ”§ è”é‚¦å­¦ä¹ ã€å·®åˆ†éšç§ç­‰æŠ€æœ¯è®©AIè®­ç»ƒæ›´æ³¨é‡éšç§ä¿æŠ¤ï¼Œå®ç°'å¯æŒç»­çš„æ•°æ®ä½¿ç”¨'ã€‚",
                    "ğŸ“Š è´Ÿè´£ä»»AIå¼€å‘æ¡†æ¶æ­£åœ¨æˆä¸ºè¡Œä¸šæ ‡å‡†ï¼Œ70%çš„ç§‘æŠ€å…¬å¸å·²å»ºç«‹AIä¼¦ç†å§”å‘˜ä¼šã€‚",
                    "ğŸš€ æŠ€æœ¯å‘å–„ï¼Œè®©AIæœåŠ¡å…¨äººç±»ã€‚å¯æŒç»­AIçš„æœ€ç»ˆç›®æ ‡æ˜¯åˆ›é€ ä¸€ä¸ªæ›´å…¬å¹³ã€æ›´ç¾å¥½çš„æ™ºèƒ½ä¸–ç•Œã€‚ #AIä¼¦ç† #æŠ€æœ¯å‘å–„"
                ]
            }
        ]
        
        # ä¸­åŒ»ç§‘æŠ€èåˆä¸»é¢˜åº“
        self.tcm_tech_topics = [
            {
                "theme": "æ™ºæ…§ä¸­åŒ»",
                "content": [
                    "ğŸ¥ æ™ºæ…§ä¸­åŒ»æ—¶ä»£æ¥ä¸´ï¼AIæ­£åœ¨é‡æ–°å®šä¹‰ä¼ ç»Ÿä¸­åŒ»è¯Šç–—æ¨¡å¼ï¼Œè®©åƒå¹´åŒ»å­¦ç„•å‘æ–°æ´»åŠ›ã€‚",
                    "ğŸ’¡ AIè¾…åŠ©ä¸­åŒ»è¯Šæ–­ç³»ç»Ÿèƒ½å¤Ÿåˆ†æèˆŒè±¡ã€è„‰è±¡æ•°æ®ï¼Œå‡†ç¡®ç‡è¾¾90%ä»¥ä¸Šï¼Œä¸ºä¼ ç»Ÿè¯Šæ–­æä¾›ç§‘å­¦æ”¯æ’‘ã€‚",
                    "ğŸ”¬ å¤§æ•°æ®æŒ–æ˜å¤æ–¹å®åº“ï¼Œä»ã€Šæœ¬è‰çº²ç›®ã€‹åˆ°ç°ä»£ä¸´åºŠï¼ŒAIå¸®åŠ©å‘ç°æ–°çš„è¯ç‰©ç»„åˆå’Œæ²»ç–—æ–¹æ¡ˆã€‚",
                    "ğŸ“Š æ™ºèƒ½èˆŒè¯Šã€è„‰è¯Šè®¾å¤‡å°†ç»éªŒä¼ æ‰¿æ•°å­—åŒ–ï¼Œè®©å¹´è½»ä¸­åŒ»å¸ˆå¿«é€ŸæŒæ¡è¯Šæ–­ç²¾é«“ã€‚",
                    "ğŸš€ ä¼ ç»Ÿæ™ºæ…§é‡è§ç°ä»£ç§‘æŠ€ï¼Œä¸­åŒ»è¯èµ°å‘ç²¾å‡†åŒ–ã€ä¸ªæ€§åŒ–çš„æ–°æ—¶ä»£ï¼ #æ™ºæ…§ä¸­åŒ» #AIè¯Šæ–­ #ä¼ ç»Ÿä¸ç°ä»£"
                ]
            },
            {
                "theme": "æ•°å­—åŒ–ä¼ æ‰¿", 
                "content": [
                    "ğŸ“š æ•°å­—åŒ–ä¼ æ‰¿è®©åƒå¹´ä¸­åŒ»æ™ºæ…§æ°¸ç»­æµä¼ ã€‚å¤ç±æ•°å­—åŒ–ã€çŸ¥è¯†å›¾è°±æ„å»ºï¼Œä¼ ç»ŸåŒ»å­¦æ’ä¸Šç§‘æŠ€ç¿…è†€ã€‚",
                    "ğŸ§  AIæ·±åº¦å­¦ä¹ ä¸­åŒ»æ€ç»´æ¨¡å¼ï¼Œä»æµ·é‡åŒ»æ¡ˆä¸­æå–è¯Šç–—è§„å¾‹ï¼Œè®©æœºå™¨ç†è§£'è¾¨è¯è®ºæ²»'çš„ç²¾é«“ã€‚",
                    "ğŸŒ å…¨çƒä¸­åŒ»çŸ¥è¯†å…±äº«å¹³å°å»ºç«‹ï¼Œè®©ä¸–ç•Œå„åœ°çš„ä¸­åŒ»å¸ˆéƒ½èƒ½è·å¾—æœ€å‰æ²¿çš„è¯Šç–—ç»éªŒã€‚",
                    "âš¡ åŒºå—é“¾æŠ€æœ¯ä¿æŠ¤ä¼ ç»Ÿæ–¹å‰‚çŸ¥è¯†äº§æƒï¼Œç¡®ä¿çè´µåŒ»å­¦é—äº§å¾—åˆ°åˆç†ä¿æŠ¤å’Œä¼ æ‰¿ã€‚",
                    "ğŸ”® æ•°å­—å­ªç”ŸæŠ€æœ¯è¿˜åŸå¤ä»£ååŒ»è¯Šç–—è¿‡ç¨‹ï¼Œä¸ºåå­¦è€…æä¾›æ²‰æµ¸å¼å­¦ä¹ ä½“éªŒã€‚ #æ•°å­—ä¼ æ‰¿ #ä¸­åŒ»æ•™è‚² #æ–‡åŒ–ç§‘æŠ€"
                ]
            },
            {
                "theme": "ç²¾å‡†ä¸­åŒ»",
                "content": [
                    "ğŸ§¬ ç²¾å‡†ä¸­åŒ»æ–°æ—¶ä»£ï¼šåŸºå› ç»„å­¦æŒ‡å¯¼ä¸ªæ€§åŒ–ç”¨è¯ï¼Œè®©'å› äººåˆ¶å®œ'æ›´åŠ ç§‘å­¦ç²¾å‡†ã€‚",
                    "ğŸ“± ä¸ªæ€§åŒ–ä½“è´¨åˆ†æAPPç»“åˆç°ä»£æ£€æµ‹æŠ€æœ¯ï¼Œå‡†ç¡®åˆ¤æ–­ä¹ç§ä½“è´¨ç±»å‹ï¼ŒæŒ‡å¯¼æ—¥å¸¸å…»ç”Ÿã€‚",
                    "âš–ï¸ é‡åŒ–ä¸­åŒ»è¾¨è¯è®ºæ²»ï¼Œå°†'æœ›é—»é—®åˆ‡'è½¬åŒ–ä¸ºå¯æµ‹é‡çš„ç”Ÿç†æŒ‡æ ‡ï¼Œæå‡è¯Šæ–­å®¢è§‚æ€§ã€‚",
                    "ğŸ¯ ç²¾å‡†é’ˆç¸ç©´ä½å®šä½ç³»ç»Ÿï¼Œç»“åˆ3Dæˆåƒå’ŒAIç®—æ³•ï¼Œç¡®ä¿æ¯ä¸€é’ˆéƒ½ç²¾å‡†åˆ°ä½ã€‚",
                    "ğŸ”„ ä¸­è¥¿åŒ»ç»“åˆè¯Šç–—æ¨¡å¼ï¼Œç°ä»£åŒ»å­¦æ£€æµ‹ + ä¸­åŒ»æ•´ä½“è°ƒç† = æœ€ä½³æ²»ç–—æ•ˆæœã€‚ #ç²¾å‡†ä¸­åŒ» #ä¸ªæ€§åŒ–åŒ»ç–— #ç§‘æŠ€å…»ç”Ÿ"
                ]
            },
            {
                "theme": "åˆ›æ–°èåˆ",
                "content": [
                    "ğŸŒ¿ åˆ›æ–°èåˆå¼€å¯ä¸­åŒ»è¯æ–°ç¯‡ç« ã€‚ç°ä»£æå–å·¥è‰ºè®©ä¸­è¯æœ‰æ•ˆæˆåˆ†æ›´çº¯å‡€ã€æ›´æ ‡å‡†åŒ–ã€‚",
                    "ğŸ“¡ è¿œç¨‹ä¸­åŒ»è¯Šç–—å¹³å°çªç ´åœ°åŸŸé™åˆ¶ï¼Œåè€ä¸­åŒ»çš„è¯Šç–—ç»éªŒæƒ åŠæ›´å¤šæ‚£è€…ã€‚",
                    "ğŸ­ æ™ºèƒ½åˆ¶è¯ç³»ç»Ÿå®ç°ä¸­è¯ç”Ÿäº§å…¨ç¨‹è´¨é‡æ§åˆ¶ï¼Œç¡®ä¿æ¯ä¸€å‘³ä¸­è¯éƒ½è¾¾åˆ°æœ€é«˜æ ‡å‡†ã€‚",
                    "ğŸ¤– ä¸­åŒ»åº·å¤æœºå™¨äººç»“åˆä¼ ç»ŸæŒ‰æ‘©æ‰‹æ³•å’Œç°ä»£åº·å¤ç†å¿µï¼Œæä¾›24å°æ—¶ä¸ªæ€§åŒ–ç†ç–—æœåŠ¡ã€‚",
                    "ğŸ’« ä¼ ç»Ÿä¸ç°ä»£çš„å®Œç¾èåˆï¼Œè®©ä¸­åŒ»è¯åœ¨æ–°æ—¶ä»£ç„•å‘æ— é™ç”Ÿæœºä¸æ´»åŠ›ï¼ #åˆ›æ–°ä¸­åŒ» #æ™ºèƒ½åˆ¶è¯ #æœªæ¥åŒ»ç–—"
                ]
            }
        ]
    
    async def generate_tcm_tech_headlines(self) -> str:
        """ç”Ÿæˆä¸­åŒ»ç§‘æŠ€èåˆå¤´æ¡"""
        try:
            logger.info("ğŸ¥ å¼€å§‹ç”Ÿæˆä¸­åŒ»ç§‘æŠ€å¤´æ¡...")
            
            # 1. ç”Ÿæˆä¸­åŒ»ç§‘æŠ€å¤´æ¡ï¼ˆæš‚æ—¶è·³è¿‡æœç´¢ä»¥é¿å…ä¸Šä¸‹æ–‡é—®é¢˜ï¼‰
            # TODO: ä¿®å¤æœç´¢ä¸Šä¸‹æ–‡é—®é¢˜åæ¢å¤
            web_results = None  # æš‚æ—¶ä½¿ç”¨fallbackå†…å®¹
            
            # 2. ç”Ÿæˆèåˆå¤´æ¡
            current_time = datetime.now(timezone.utc).strftime("%Y-%m-%d")
            headlines = self._format_tcm_tech_headlines(web_results, current_time)
            
            logger.info("âœ… ä¸­åŒ»ç§‘æŠ€å¤´æ¡ç”Ÿæˆå®Œæˆ")
            return headlines
            
        except Exception as e:
            logger.error(f"âŒ ä¸­åŒ»ç§‘æŠ€å¤´æ¡ç”Ÿæˆå¤±è´¥: {e}")
            return self._get_fallback_tcm_headlines()
    
    def _format_tcm_tech_headlines(self, web_data: Any, date: str) -> str:
        """æ ¼å¼åŒ–ä¸­åŒ»ç§‘æŠ€å¤´æ¡"""
        templates = [
            f"ğŸ¥ ä»Šæ—¥ä¸­åŒ»ç§‘æŠ€å¤´æ¡ {date}\n\nğŸ’¡ AIåŠ©åŠ›ä¸­åŒ»è¯Šæ–­æŠ€æœ¯æ–°çªç ´\nğŸŒ¿ ä¼ ç»ŸåŒ»å­¦ä¸ç°ä»£ç§‘æŠ€æ·±åº¦èåˆ\nğŸš€ æ•°å­—åŒ–ä¸­åŒ»ä¸ºå¥åº·èµ‹èƒ½ï¼ #ä¸­åŒ»ç§‘æŠ€ #æ™ºæ…§åŒ»ç–— #ä¼ ç»Ÿåˆ›æ–°",
            f"ğŸ“± ä»Šæ—¥ä¸­åŒ»ç§‘æŠ€å¤´æ¡ {date}\n\nğŸ§  äººå·¥æ™ºèƒ½å­¦ä¹ ä¸­åŒ»å¤å…¸ç†è®º\nâš–ï¸ ç²¾å‡†åŒ»ç–—è®©ä¸­åŒ»æ›´ç§‘å­¦åŒ–\nğŸŒŸ åƒå¹´æ™ºæ…§é‡è§ç°ä»£æŠ€æœ¯ï¼ #æ•°å­—ä¸­åŒ» #AIåŒ»ç–— #ç§‘æŠ€ä¼ æ‰¿",
            f"ğŸ”¬ ä»Šæ—¥ä¸­åŒ»ç§‘æŠ€å¤´æ¡ {date}\n\nğŸ“Š å¤§æ•°æ®æŒ–æ˜ä¸­åŒ»è¯å®åº“\nğŸ¯ ä¸ªæ€§åŒ–ä¸­åŒ»è¯Šç–—æˆä¸ºç°å®\nğŸ’« ä¼ ç»Ÿä¸ç°ä»£å®Œç¾ç»“åˆï¼ #ä¸­åŒ»å¤§æ•°æ® #ä¸ªæ€§åŒ–åŒ»ç–— #åˆ›æ–°åŒ»å­¦"
        ]
        
        import random
        return random.choice(templates)
    
    def _get_fallback_tcm_headlines(self) -> str:
        """å¤‡ç”¨ä¸­åŒ»ç§‘æŠ€å¤´æ¡"""
        date = datetime.now(timezone.utc).strftime("%Y-%m-%d")
        return f"ğŸ¥ ä»Šæ—¥ä¸­åŒ»ç§‘æŠ€å¤´æ¡ {date}\n\nğŸ’¡ æ™ºæ…§ä¸­åŒ»åŠ©åŠ›ç²¾å‡†è¯Šç–—\nğŸŒ¿ ä¼ ç»ŸåŒ»å­¦ç§‘æŠ€åŒ–å‘å±•æŒç»­æ¨è¿›\nğŸš€ ä¸­åŒ»è¯ç°ä»£åŒ–è¿›ç¨‹åŠ é€Ÿï¼ #ä¸­åŒ»ç§‘æŠ€ #æ™ºæ…§åŒ»ç–— #æ•°å­—å¥åº·"
    
    async def generate_wisdom_ai_thread(self) -> List[str]:
        """ç”ŸæˆAI+ä¼ ç»Ÿæ™ºæ…§çº¿ç¨‹ï¼ˆè½®æ¢å¯æŒç»­AIå’Œä¸­åŒ»ç§‘æŠ€ï¼‰"""
        try:
            import random
            
            # 50%æ¦‚ç‡é€‰æ‹©ä¼ ç»Ÿå¯æŒç»­AIï¼Œ50%é€‰æ‹©ä¸­åŒ»ç§‘æŠ€
            if random.random() < 0.5:
                logger.info("ğŸ¤– ç”Ÿæˆå¯æŒç»­AIçº¿ç¨‹")
                return await self.generate_sustainable_ai_thread()
            else:
                logger.info("ğŸ¥ ç”Ÿæˆä¸­åŒ»ç§‘æŠ€æ™ºæ…§çº¿ç¨‹")
                selected_topic = random.choice(self.tcm_tech_topics)
                logger.info(f"âœ… é€‰æ‹©ä¸­åŒ»ç§‘æŠ€ä¸»é¢˜: {selected_topic['theme']}")
                return selected_topic['content']
                
        except Exception as e:
            logger.error(f"âŒ æ™ºæ…§çº¿ç¨‹ç”Ÿæˆå¤±è´¥: {e}")
            # é™çº§åˆ°å¯æŒç»­AIå†…å®¹
            return await self.generate_sustainable_ai_thread()
    
    async def generate_daily_tcm_tech_content(self) -> str:
        """ç”Ÿæˆæ¯æ—¥ä¸­åŒ»ç§‘æŠ€ä¸“é¢˜å†…å®¹"""
        try:
            logger.info("ğŸ¥ å¼€å§‹ç”Ÿæˆæ¯æ—¥ä¸­åŒ»ç§‘æŠ€ä¸“é¢˜å†…å®¹...")
            
            # é€‰æ‹©ä¸€ä¸ªä¸­åŒ»ç§‘æŠ€ä¸»é¢˜çš„ç¬¬ä¸€æ¡å†…å®¹ä½œä¸ºä¸“é¢˜
            import random
            selected_topic = random.choice(self.tcm_tech_topics)
            theme = selected_topic['theme']
            
            # åˆ›å»ºä¸“é¢˜å†…å®¹
            templates = [
                f"ğŸ¥ æ¯æ—¥ä¸­åŒ»ç§‘æŠ€ä¸“é¢˜\n\nä¸»é¢˜ï¼š{theme}\n\n{selected_topic['content'][0]}\n\nä¼ ç»Ÿæ™ºæ…§ä¸ç°ä»£ç§‘æŠ€çš„å®Œç¾ç»“åˆï¼Œæ­£åœ¨å¼€åˆ›åŒ»ç–—å¥åº·çš„æ–°çºªå…ƒï¼",
                f"ğŸ’¡ ä¸­åŒ»ç§‘æŠ€æ–°è§†è§’\n\nèšç„¦ï¼š{theme}\n\n{selected_topic['content'][1]}\n\nè®©æˆ‘ä»¬ä¸€èµ·è§è¯åƒå¹´åŒ»å­¦åœ¨æ•°å­—æ—¶ä»£çš„åä¸½è½¬èº«ï¼",
                f"ğŸŒ¿ ä¼ ç»Ÿä¸åˆ›æ–°èåˆ\n\nä»Šæ—¥è¯é¢˜ï¼š{theme}\n\n{selected_topic['content'][2]}\n\nç§‘æŠ€ä¸ºä¼ ç»ŸåŒ»å­¦æ’ä¸Šç¿…è†€ï¼Œæœªæ¥å¥åº·è§¦æ‰‹å¯åŠï¼"
            ]
            
            content = random.choice(templates)
            
            # ç¡®ä¿å­—æ•°é™åˆ¶
            if len(content) > 280:
                content = content[:277] + "..."
                
            logger.info(f"âœ… ä¸­åŒ»ç§‘æŠ€ä¸“é¢˜å†…å®¹ç”Ÿæˆå®Œæˆï¼š{theme}")
            return content
            
        except Exception as e:
            logger.error(f"âŒ ä¸­åŒ»ç§‘æŠ€ä¸“é¢˜ç”Ÿæˆå¤±è´¥: {e}")
            return self._get_fallback_tcm_daily_content()
    
    def _get_fallback_tcm_daily_content(self) -> str:
        """å¤‡ç”¨ä¸­åŒ»ç§‘æŠ€ä¸“é¢˜å†…å®¹"""
        fallback_contents = [
            "ğŸ¥ æ¯æ—¥ä¸­åŒ»ç§‘æŠ€ä¸“é¢˜\n\nğŸ’¡ AIæŠ€æœ¯æ­£åœ¨é©å‘½æ€§åœ°æ”¹å˜ä¼ ç»Ÿä¸­åŒ»è¯Šç–—æ¨¡å¼ï¼Œè®©å¤è€çš„åŒ»å­¦æ™ºæ…§ç„•å‘æ–°çš„ç”Ÿæœºã€‚\n\nğŸš€ ä¼ ç»Ÿä¸ç°ä»£çš„ç¢°æ’ï¼Œæ­£åœ¨åˆ›é€ åŒ»ç–—å¥åº·çš„æ— é™å¯èƒ½ï¼ #ä¸­åŒ»ç§‘æŠ€ #AIåŒ»ç–—",
            "ğŸŒ¿ ä¸­åŒ»ç§‘æŠ€æ–°è§†è§’\n\nğŸ“± æ•°å­—åŒ–æŠ€æœ¯è®©ä¸­åŒ»è¯Šæ–­æ›´åŠ ç²¾å‡†ï¼Œä¸ªæ€§åŒ–æ²»ç–—æˆä¸ºç°å®ã€‚\n\nâš¡ åƒå¹´æ™ºæ…§é‡è§ç°ä»£ç§‘æŠ€ï¼Œå¥åº·ç®¡ç†è¿›å…¥å…¨æ–°æ—¶ä»£ï¼ #æ•°å­—ä¸­åŒ» #ç²¾å‡†åŒ»ç–—",
            "ğŸ’« ä¼ ç»Ÿæ™ºæ…§æ–°ç¯‡ç« \n\nğŸ”¬ ç°ä»£ç§‘æŠ€éªŒè¯å¤è€æ–¹å‰‚ï¼Œä¸­è¥¿åŒ»ç»“åˆå¼€åˆ›åŒ»ç–—æ–°æ¨¡å¼ã€‚\n\nğŸ¯ è®©ç§‘æŠ€ä¸ºä¼ ç»ŸåŒ»å­¦èµ‹èƒ½ï¼Œå…±åŒå®ˆæŠ¤äººç±»å¥åº·ï¼ #ä¸­è¥¿ç»“åˆ #åˆ›æ–°åŒ»ç–—"
        ]
        
        import random
        return random.choice(fallback_contents)

    async def generate_daily_headlines(self) -> str:
        """ç”Ÿæˆä»Šæ—¥ç§‘æŠ€å¤´æ¡"""
        try:
            logger.info("ğŸ” å¼€å§‹ç”Ÿæˆä»Šæ—¥ç§‘æŠ€å¤´æ¡...")
            
            # 1. è·å–æœ€æ–°ç§‘æŠ€æ–°é—»ï¼ˆæš‚æ—¶è·³è¿‡æœç´¢ï¼‰
            # TODO: ä¿®å¤æœç´¢ä¸Šä¸‹æ–‡é—®é¢˜åæ¢å¤  
            web_results = None  # æš‚æ—¶ä½¿ç”¨fallbackå†…å®¹
            
            # 2. è·å–Twitterè¶‹åŠ¿
            twitter_trends = ""
            try:
                tools = await _get_all_mcp_tools()
                if "get_trends" in tools:
                    trends_result = await tools["get_trends"].ainvoke({"woeid": 1})
                    twitter_trends = str(trends_result)[:300]
            except Exception as e:
                logger.warning(f"è·å–Twitterè¶‹åŠ¿å¤±è´¥: {e}")
            
            # 3. ç”Ÿæˆå¤´æ¡å†…å®¹
            current_time = datetime.now(timezone.utc).strftime("%Y-%m-%d")
            
            headlines = self._format_tech_headlines(web_results, twitter_trends, current_time)
            
            logger.info("âœ… ä»Šæ—¥ç§‘æŠ€å¤´æ¡ç”Ÿæˆå®Œæˆ")
            return headlines
            
        except Exception as e:
            logger.error(f"âŒ å¤´æ¡ç”Ÿæˆå¤±è´¥: {e}")
            return self._get_fallback_headlines()
    
    def _format_tech_headlines(self, web_data: Any, twitter_data: str, date: str) -> str:
        """æ ¼å¼åŒ–ç§‘æŠ€å¤´æ¡å†…å®¹"""
        # åˆ†æç½‘ç»œæœç´¢ç»“æœ
        key_topics = []
        if isinstance(web_data, dict) and 'results' in web_data:
            for result in web_data['results'][:3]:
                if isinstance(result, dict):
                    title = result.get('title', '')
                    if any(keyword in title.lower() for keyword in ['ai', 'tech', 'äººå·¥æ™ºèƒ½', 'ç§‘æŠ€', 'innovation']):
                        key_topics.append(title[:50])
        
        # ç”Ÿæˆå¤´æ¡
        if key_topics:
            main_topic = key_topics[0]
            headlines = f"ğŸ“° ä»Šæ—¥ç§‘æŠ€å¤´æ¡ {date}\n\nğŸ”¥ {main_topic}\n"
            if len(key_topics) > 1:
                headlines += f"ğŸ’¡ {key_topics[1]}\n"
            headlines += f"\nç§‘æŠ€åˆ›æ–°æ°¸ä¸åœæ­‡ï¼Œè®©æˆ‘ä»¬ä¸€èµ·å…³æ³¨æœ€æ–°å‘å±•ï¼ #ç§‘æŠ€å¤´æ¡ #AI #åˆ›æ–°"
        else:
            headlines = self._get_fallback_headlines()
        
        # ç¡®ä¿å­—æ•°é™åˆ¶
        if len(headlines) > 280:
            headlines = headlines[:277] + "..."
        
        return headlines
    
    def _get_fallback_headlines(self) -> str:
        """å¤‡ç”¨å¤´æ¡å†…å®¹"""
        date = datetime.now(timezone.utc).strftime("%Y-%m-%d")
        fallback_headlines = [
            f"ğŸ“° ä»Šæ—¥ç§‘æŠ€å¤´æ¡ {date}\n\nğŸ¤– AIæŠ€æœ¯æŒç»­çªç ´ï¼Œå¤§æ¨¡å‹æ•ˆç‡ä¸æ–­æå‡\nğŸ’¡ é‡å­è®¡ç®—ç ”ç©¶å–å¾—æ–°è¿›å±•\nğŸš€ ç§‘æŠ€åˆ›æ–°æ¨åŠ¨ç¤¾ä¼šè¿›æ­¥ï¼Œæœªæ¥å€¼å¾—æœŸå¾…ï¼ #ç§‘æŠ€å¤´æ¡ #AI #åˆ›æ–°",
            f"ğŸ“° ä»Šæ—¥ç§‘æŠ€å¤´æ¡ {date}\n\nğŸ”‹ ç»¿è‰²ç§‘æŠ€æˆä¸ºå‘å±•æ–°è¶‹åŠ¿\nğŸŒ è¾¹ç¼˜è®¡ç®—ä¸äº‘è®¡ç®—æ·±åº¦èåˆ\nâš¡ æŠ€æœ¯å˜é©æ­£åœ¨æ”¹å˜æˆ‘ä»¬çš„ç”Ÿæ´»æ–¹å¼ï¼ #ç§‘æŠ€å¤´æ¡ #ç»¿è‰²ç§‘æŠ€ #æœªæ¥",
            f"ğŸ“° ä»Šæ—¥ç§‘æŠ€å¤´æ¡ {date}\n\nğŸ§  ç¥ç»ç½‘ç»œæ¶æ„æŒç»­åˆ›æ–°\nğŸ” ç½‘ç»œå®‰å…¨æŠ€æœ¯æ—¥ç›Šé‡è¦\nğŸŒŸ ç§‘æŠ€è®©ä¸–ç•Œå˜å¾—æ›´åŠ æ™ºèƒ½å’Œå®‰å…¨ï¼ #ç§‘æŠ€å¤´æ¡ #ç¥ç»ç½‘ç»œ #ç½‘ç»œå®‰å…¨"
        ]
        
        import random
        return random.choice(fallback_headlines)
    
    async def generate_sustainable_ai_thread(self) -> List[str]:
        """ç”Ÿæˆå¯æŒç»­AIçº¿ç¨‹å†…å®¹"""
        try:
            logger.info("ğŸŒ± å¼€å§‹ç”Ÿæˆå¯æŒç»­AIçº¿ç¨‹...")
            
            # éšæœºé€‰æ‹©ä¸€ä¸ªä¸»é¢˜
            import random
            selected_topic = random.choice(self.sustainable_ai_topics)
            
            logger.info(f"âœ… é€‰æ‹©ä¸»é¢˜: {selected_topic['theme']}")
            return selected_topic['content']
            
        except Exception as e:
            logger.error(f"âŒ å¯æŒç»­AIçº¿ç¨‹ç”Ÿæˆå¤±è´¥: {e}")
            return self._get_fallback_ai_thread()
    
    def _get_fallback_ai_thread(self) -> List[str]:
        """å¤‡ç”¨AIçº¿ç¨‹å†…å®¹"""
        return [
            "ğŸŒ± å¯æŒç»­AIå‘å±•æ˜¯å½“ä»Šç§‘æŠ€ç•Œçš„é‡è¦è¯¾é¢˜ã€‚åœ¨è¿½æ±‚AIæ€§èƒ½çš„åŒæ—¶ï¼Œæˆ‘ä»¬ä¹Ÿè¦å…³æ³¨å…¶ç¯å¢ƒå½±å“ã€‚",
            "ğŸ’¡ å¤§å‹AIæ¨¡å‹çš„è®­ç»ƒå’Œéƒ¨ç½²æ¶ˆè€—å¤§é‡èƒ½æºã€‚ç ”ç©¶è¡¨æ˜ï¼Œä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹çš„è®­ç»ƒç›¸å½“äºå‡ åä¸‡å…¬é‡Œçš„æ±½è½¦è¡Œé©¶ã€‚",
            "ğŸ”§ è§£å†³æ–¹æ¡ˆæ­£åœ¨æ¶Œç°ï¼šæ¨¡å‹å‹ç¼©ã€é«˜æ•ˆç®—æ³•ã€ç»¿è‰²æ•°æ®ä¸­å¿ƒç­‰æŠ€æœ¯æ­£åœ¨è®©AIå˜å¾—æ›´åŠ ç¯ä¿ã€‚",
            "ğŸ“Š ç›®æ ‡å¾ˆæ˜ç¡®ï¼šåœ¨2030å¹´å‰å°†AIè®¡ç®—çš„ç¢³è¶³è¿¹å‡å°‘50%ï¼ŒåŒæ—¶ä¿æŒç”šè‡³æå‡AIçš„èƒ½åŠ›ã€‚",
            "ğŸš€ è®©æˆ‘ä»¬å…±åŒæ¨åŠ¨å¯æŒç»­AIçš„å‘å±•ï¼Œä¸ºåœ°çƒå’Œæœªæ¥è´Ÿè´£ï¼æ¯ä¸ªäººéƒ½å¯ä»¥ä¸ºç»¿è‰²AIè´¡çŒ®åŠ›é‡ã€‚ #å¯æŒç»­AI #ç»¿è‰²è®¡ç®— #ç¯ä¿ç§‘æŠ€"
        ]
    
    async def find_retweet_target(self) -> Optional[Dict[str, str]]:
        """æ‰¾åˆ°å€¼å¾—è½¬å‘çš„ä¼˜è´¨å†…å®¹"""
        try:
            logger.info("ğŸ” æœç´¢ä¼˜è´¨ç§‘æŠ€å†…å®¹ç”¨äºè½¬å‘...")
            
            # æœç´¢é«˜è´¨é‡ç§‘æŠ€æ¨æ–‡
            tools = await _get_all_mcp_tools()
            if "advanced_search_twitter" not in tools:
                logger.warning("Twitteræœç´¢å·¥å…·ä¸å¯ç”¨")
                return None
            
            # æœç´¢æŸ¥è¯¢ç»„åˆ
            search_queries = [
                "from:OpenAI OR from:AnthropicAI OR from:DeepMind recent breakthroughs",
                "artificial intelligence research breakthrough min_faves:100",
                "sustainable AI green computing innovation",
                "quantum computing progress latest",
                "#MachineLearning #AI paper findings"
            ]
            
            import random
            query = random.choice(search_queries)
            
            search_result = await tools["advanced_search_twitter"].ainvoke({"llm_text": query})
            
            # è§£ææœç´¢ç»“æœ
            if isinstance(search_result, dict) and search_result.get('success'):
                tweets = search_result.get('data', {}).get('tweets', [])
                if tweets and len(tweets) > 0:
                    # é€‰æ‹©ç¬¬ä¸€æ¡æ¨æ–‡
                    target_tweet = tweets[0]
                    tweet_id = target_tweet.get('id')
                    tweet_text = target_tweet.get('text', '')
                    author = target_tweet.get('author', {}).get('username', 'unknown')
                    
                    if tweet_id and len(tweet_text) > 50:  # ç¡®ä¿å†…å®¹æœ‰è¶³å¤Ÿä»·å€¼
                        return {
                            "tweet_id": tweet_id,
                            "original_text": tweet_text[:100] + "..." if len(tweet_text) > 100 else tweet_text,
                            "author": author,
                            "comment": self._generate_retweet_comment(tweet_text)
                        }
            
            logger.warning("æœªæ‰¾åˆ°åˆé€‚çš„è½¬å‘ç›®æ ‡")
            return None
            
        except Exception as e:
            logger.error(f"âŒ æœç´¢è½¬å‘ç›®æ ‡å¤±è´¥: {e}")
            return None
    
    def _generate_retweet_comment(self, original_text: str) -> str:
        """ä¸ºè½¬å‘ç”Ÿæˆè¯„è®º"""
        comments = [
            "ğŸ’¡ è¿™ä¸ªè§‚ç‚¹å¾ˆæœ‰å¯å‘æ€§ï¼AIæŠ€æœ¯çš„å‘å±•ç¡®å®éœ€è¦æˆ‘ä»¬ä»å¤šä¸ªè§’åº¦æ€è€ƒã€‚",
            "ğŸ¯ è¯´å¾—å¾ˆå¥½ï¼æŠ€æœ¯åˆ›æ–°ä¸è´Ÿè´£ä»»å‘å±•å¹¶ä¸çŸ›ç›¾ï¼Œå…³é”®åœ¨äºæ‰¾åˆ°å¹³è¡¡ç‚¹ã€‚", 
            "ğŸ”¬ éå¸¸æœ‰ä»·å€¼çš„åˆ†äº«ï¼è¿™ç±»ç ”ç©¶æˆæœå¯¹æ•´ä¸ªè¡Œä¸šéƒ½æœ‰é‡è¦æ„ä¹‰ã€‚",
            "âš¡ èµåŒè¿™ä¸ªçœ‹æ³•ï¼å‰æ²¿æŠ€æœ¯çš„å‘å±•æ€»æ˜¯å……æ»¡æŒ‘æˆ˜å’Œæœºé‡ã€‚",
            "ğŸŒŸ ç²¾å½©çš„è§è§£ï¼ç§‘æŠ€è¿›æ­¥çš„æ¯ä¸€æ­¥éƒ½å€¼å¾—æˆ‘ä»¬æ·±å…¥æ€è€ƒå’Œè®¨è®ºã€‚"
        ]
        
        import random
        return random.choice(comments)
    
    async def generate_weekly_recap(self) -> str:
        """ç”Ÿæˆæœ¬å‘¨ç§‘æŠ€è¶‹åŠ¿å›é¡¾"""
        try:
            logger.info("ğŸ“Š å¼€å§‹ç”Ÿæˆæœ¬å‘¨ç§‘æŠ€è¶‹åŠ¿å›é¡¾...")
            
            # è·å–æœ¬å‘¨çš„ç§‘æŠ€æ–°é—»ï¼ˆæš‚æ—¶è·³è¿‡æœç´¢ï¼‰
            # TODO: ä¿®å¤æœç´¢ä¸Šä¸‹æ–‡é—®é¢˜åæ¢å¤
            web_results = None  # æš‚æ—¶ä½¿ç”¨fallbackå†…å®¹
            
            current_date = datetime.now(timezone.utc)
            week_start = current_date - timedelta(days=7)
            
            recap_content = self._format_weekly_recap(web_results, week_start.strftime("%m-%d"), current_date.strftime("%m-%d"))
            
            logger.info("âœ… æœ¬å‘¨å›é¡¾ç”Ÿæˆå®Œæˆ")
            return recap_content
            
        except Exception as e:
            logger.error(f"âŒ æœ¬å‘¨å›é¡¾ç”Ÿæˆå¤±è´¥: {e}")
            return self._get_fallback_weekly_recap()
    
    def _format_weekly_recap(self, web_data: Any, start_date: str, end_date: str) -> str:
        """æ ¼å¼åŒ–æœ¬å‘¨å›é¡¾å†…å®¹"""
        # åˆ†ææœ¬å‘¨å…³é”®äº‹ä»¶
        key_events = []
        if isinstance(web_data, dict) and 'results' in web_data:
            for result in web_data['results'][:3]:
                if isinstance(result, dict):
                    title = result.get('title', '')
                    if any(keyword in title.lower() for keyword in ['ai', 'tech', 'breakthrough', 'innovation']):
                        key_events.append(title[:60])
        
        recap = f"ğŸ“Š æœ¬å‘¨ç§‘æŠ€è¶‹åŠ¿å›é¡¾ ({start_date} - {end_date})\n\n"
        
        if key_events:
            for i, event in enumerate(key_events, 1):
                recap += f"{i}ï¸âƒ£ {event}\n"
        else:
            recap += "ğŸ¤– AIæŠ€æœ¯æŒç»­è¿›æ­¥\nğŸ’¡ åˆ›æ–°åº”ç”¨ä¸æ–­æ¶Œç°\nğŸŒ ç§‘æŠ€ç”Ÿæ€æ—¥ç›Šå®Œå–„\n"
        
        recap += f"\nç§‘æŠ€å‘å±•æ°¸ä¸æ­¢æ­¥ï¼Œè®©æˆ‘ä»¬æœŸå¾…ä¸‹å‘¨æ›´å¤šç²¾å½©ï¼ #æœ¬å‘¨å›é¡¾ #ç§‘æŠ€è¶‹åŠ¿ #åˆ›æ–°"
        
        # ç¡®ä¿å­—æ•°é™åˆ¶
        if len(recap) > 280:
            recap = recap[:277] + "..."
        
        return recap
    
    def _get_fallback_weekly_recap(self) -> str:
        """å¤‡ç”¨æœ¬å‘¨å›é¡¾å†…å®¹"""
        current_date = datetime.now(timezone.utc)
        week_start = current_date - timedelta(days=7)
        
        return f"""ğŸ“Š æœ¬å‘¨ç§‘æŠ€è¶‹åŠ¿å›é¡¾ ({week_start.strftime("%m-%d")} - {current_date.strftime("%m-%d")})

1ï¸âƒ£ AIå¤§æ¨¡å‹æ€§èƒ½æŒç»­ä¼˜åŒ–
2ï¸âƒ£ ç»¿è‰²è®¡ç®—ç†å¿µæ·±å…¥äººå¿ƒ  
3ï¸âƒ£ è¾¹ç¼˜AIåº”ç”¨åœºæ™¯æ‰©å±•
4ï¸âƒ£ å¼€æºæŠ€æœ¯ç”Ÿæ€ç¹è£

ç§‘æŠ€åˆ›æ–°çš„è„šæ­¥ä»æœªåœæ­‡ï¼Œè®©æˆ‘ä»¬ä¸€èµ·è¿æ¥æ›´åŠ æ™ºèƒ½çš„æœªæ¥ï¼ #æœ¬å‘¨å›é¡¾ #ç§‘æŠ€è¶‹åŠ¿ #AIå‘å±•"""


if __name__ == "__main__":
    # æµ‹è¯•å†…å®¹ç”Ÿæˆå™¨
    async def test_generator():
        generator = TechContentGenerator()
        
        print("=== æµ‹è¯•ä»Šæ—¥ç§‘æŠ€å¤´æ¡ ===")
        headlines = await generator.generate_daily_headlines()
        print(headlines)
        print(f"å­—æ•°: {len(headlines)}\n")
        
        print("=== æµ‹è¯•å¯æŒç»­AIçº¿ç¨‹ ===")
        ai_thread = await generator.generate_sustainable_ai_thread()
        for i, tweet in enumerate(ai_thread, 1):
            print(f"{i}. {tweet} (å­—æ•°: {len(tweet)})")
        print()
        
        print("=== æµ‹è¯•è½¬å‘ç›®æ ‡æœç´¢ ===")
        retweet_target = await generator.find_retweet_target()
        if retweet_target:
            print(f"ç›®æ ‡æ¨æ–‡: {retweet_target['original_text']}")
            print(f"è¯„è®º: {retweet_target['comment']}")
        else:
            print("æœªæ‰¾åˆ°è½¬å‘ç›®æ ‡")
        print()
        
        print("=== æµ‹è¯•æœ¬å‘¨å›é¡¾ ===")
        weekly_recap = await generator.generate_weekly_recap()
        print(weekly_recap)
        print(f"å­—æ•°: {len(weekly_recap)}")
    
    asyncio.run(test_generator())