#!/usr/bin/env python3
"""æ¯æ—¥ç§‘æŠ€å†…å®¹å‘å¸ƒå™¨ - æ•´åˆæ‰€æœ‰æ¯æ—¥å‘å¸ƒåŠŸèƒ½

å‘å¸ƒæ—¶é—´è¡¨:
08:00 - ä»Šæ—¥ç§‘æŠ€å¤´æ¡ (Tech Headlines + TCM Tech)
12:00 - AI+ä¼ ç»Ÿæ™ºæ…§çº¿ç¨‹ (AI/TCM Wisdom Thread)  
14:00 - ä¸­åŒ»ç§‘æŠ€ä¸“é¢˜ (Daily TCM Tech Focus)
16:00 - æ¨¡æ‹Ÿè½¬å‘å†…å®¹ (Curated Retweet)
20:00 - æœ¬å‘¨è¶‹åŠ¿å›é¡¾ (Weekly Recap, ä»…å‘¨æ—¥)
"""

import asyncio
import logging
from datetime import datetime, timezone
from typing import Dict, Any, Optional
from pathlib import Path

from react_agent.content_generator import TechContentGenerator
from react_agent.thread_creator import TwitterThreadCreator, ThreadResult
from react_agent.content_reviewer import ContentReviewSystem
from react_agent.tools import post_tweet, quote_tweet

logger = logging.getLogger(__name__)


class DailyTechPublisher:
    """æ¯æ—¥ç§‘æŠ€å†…å®¹å‘å¸ƒå™¨"""
    
    def __init__(self, use_review_system: bool = True):
        self.content_generator = TechContentGenerator()
        self.thread_creator = TwitterThreadCreator()
        self.review_system = ContentReviewSystem() if use_review_system else None
        
        # åˆ›å»ºæ—¥å¿—ç›®å½•
        self.log_dir = Path("logs/daily_publisher")
        self.log_dir.mkdir(parents=True, exist_ok=True)
    
    async def publish_approved_content(self) -> Dict[str, Any]:
        """å‘å¸ƒå·²å®¡æ ¸é€šè¿‡çš„å†…å®¹"""
        if not self.review_system:
            return {"error": "å¤æŸ¥ç³»ç»Ÿæœªå¯ç”¨"}
        
        try:
            logger.info("ğŸ“‹ å¼€å§‹å‘å¸ƒå·²å®¡æ ¸é€šè¿‡çš„å†…å®¹")
            approved_content = await self.review_system.get_approved_content()
            
            if not approved_content:
                logger.info("âœ… æ²¡æœ‰å¾…å‘å¸ƒçš„å·²å®¡æ ¸å†…å®¹")
                return {"message": "æ²¡æœ‰å¾…å‘å¸ƒçš„å†…å®¹", "published": 0}
            
            published_count = 0
            results = []
            
            for draft in approved_content:
                try:
                    if isinstance(draft.content, list):
                        # å‘å¸ƒçº¿ç¨‹
                        thread_result = await self.thread_creator.create_thread(draft.content)
                        if thread_result.success:
                            await self.review_system.mark_as_published(draft.draft_id, thread_result.tweet_ids)
                            published_count += 1
                            results.append({
                                "draft_id": draft.draft_id,
                                "type": "thread",
                                "tweet_ids": thread_result.tweet_ids,
                                "success": True
                            })
                            logger.info(f"âœ… çº¿ç¨‹å‘å¸ƒæˆåŠŸ: {draft.draft_id}")
                    else:
                        # å‘å¸ƒå•æ¡æ¨æ–‡
                        result = await post_tweet(draft.content)
                        if result and result.get('success'):
                            tweet_id = result.get('data', {}).get('id')
                            await self.review_system.mark_as_published(draft.draft_id, [tweet_id])
                            published_count += 1
                            results.append({
                                "draft_id": draft.draft_id,
                                "type": "single",
                                "tweet_ids": [tweet_id],
                                "success": True
                            })
                            logger.info(f"âœ… æ¨æ–‡å‘å¸ƒæˆåŠŸ: {draft.draft_id}")
                        else:
                            results.append({
                                "draft_id": draft.draft_id,
                                "success": False,
                                "error": result.get('message', 'å‘å¸ƒå¤±è´¥') if result else 'å‘å¸ƒå¤±è´¥'
                            })
                            logger.error(f"âŒ æ¨æ–‡å‘å¸ƒå¤±è´¥: {draft.draft_id}")
                            
                except Exception as e:
                    results.append({
                        "draft_id": draft.draft_id,
                        "success": False,
                        "error": str(e)
                    })
                    logger.error(f"âŒ å‘å¸ƒå‡ºé”™ {draft.draft_id}: {e}")
            
            return {
                "message": f"å‘å¸ƒå®Œæˆï¼ŒæˆåŠŸ {published_count}/{len(approved_content)} æ¡",
                "published": published_count,
                "total": len(approved_content),
                "results": results
            }
            
        except Exception as e:
            logger.error(f"âŒ å‘å¸ƒå·²å®¡æ ¸å†…å®¹å‡ºé”™: {e}")
            return {"error": str(e)}
    
    async def create_content_drafts_for_review(self) -> Dict[str, Any]:
        """åˆ›å»ºå†…å®¹è‰ç¨¿ä¾›å®¡æ ¸ï¼ˆæ¯æ—¥06:30æ‰§è¡Œï¼‰"""
        if not self.review_system:
            return {"error": "å¤æŸ¥ç³»ç»Ÿæœªå¯ç”¨"}
            
        try:
            logger.info("ğŸ“ å¼€å§‹åˆ›å»ºæ¯æ—¥å†…å®¹è‰ç¨¿")
            created_drafts = []
            
            # åˆ›å»ºå„ç±»å†…å®¹è‰ç¨¿
            draft_tasks = [
                ("headlines", self.content_generator.generate_daily_headlines),
                ("tcm_headlines", self.content_generator.generate_tcm_tech_headlines), 
                ("ai_thread", self.content_generator.generate_wisdom_ai_thread),
                ("tcm_focus", self.content_generator.generate_daily_tcm_tech_content),
            ]
            
            # å‘¨æ—¥æ·»åŠ å‘¨æŠ¥
            current_time = datetime.now(timezone.utc)
            if current_time.weekday() == 6:  # Sunday
                draft_tasks.append(("weekly_recap", self.content_generator.generate_weekly_recap))
            
            for content_type, generator_func in draft_tasks:
                try:
                    content = await generator_func()
                    metadata = {
                        "generated_at": current_time.isoformat(),
                        "content_type": content_type
                    }
                    
                    draft_id = await self.review_system.create_draft(content_type, content, metadata)
                    created_drafts.append({
                        "draft_id": draft_id,
                        "content_type": content_type,
                        "success": True
                    })
                    logger.info(f"âœ… åˆ›å»ºè‰ç¨¿: {draft_id}")
                    
                except Exception as e:
                    created_drafts.append({
                        "content_type": content_type,
                        "success": False,
                        "error": str(e)
                    })
                    logger.error(f"âŒ åˆ›å»ºè‰ç¨¿å¤±è´¥ {content_type}: {e}")
            
            return {
                "message": f"è‰ç¨¿åˆ›å»ºå®Œæˆ: {len([d for d in created_drafts if d['success']])}/{len(created_drafts)}",
                "drafts": created_drafts
            }
            
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºå†…å®¹è‰ç¨¿å‡ºé”™: {e}")
            return {"error": str(e)}
        
    async def publish_morning_headlines(self) -> Dict[str, Any]:
        """08:00 å‘å¸ƒä»Šæ—¥ç§‘æŠ€å¤´æ¡ï¼ˆèåˆä¸­åŒ»ç§‘æŠ€ï¼‰"""
        try:
            logger.info("ğŸ“° å¼€å§‹å‘å¸ƒä»Šæ—¥ç§‘æŠ€å¤´æ¡")
            current_time = datetime.now(timezone.utc)
            
            # 50%æ¦‚ç‡å‘å¸ƒä¼ ç»Ÿç§‘æŠ€å¤´æ¡ï¼Œ50%å‘å¸ƒä¸­åŒ»ç§‘æŠ€å¤´æ¡
            import random
            if random.random() < 0.5:
                logger.info("ğŸ”¬ ç”Ÿæˆä¼ ç»Ÿç§‘æŠ€å¤´æ¡")
                headlines = await self.content_generator.generate_daily_headlines()
            else:
                logger.info("ğŸ¥ ç”Ÿæˆä¸­åŒ»ç§‘æŠ€å¤´æ¡")
                headlines = await self.content_generator.generate_tcm_tech_headlines()
            
            # å‘å¸ƒæ¨æ–‡
            result = await post_tweet(headlines)
            
            publish_result = {
                "task": "morning_headlines",
                "time": current_time.isoformat(),
                "success": False,
                "content": headlines,
                "tweet_id": None,
                "error": None
            }
            
            if result and result.get('success'):
                tweet_id = result.get('data', {}).get('id')
                publish_result.update({
                    "success": True,
                    "tweet_id": tweet_id,
                })
                logger.info(f"âœ… ä»Šæ—¥ç§‘æŠ€å¤´æ¡å‘å¸ƒæˆåŠŸ: {tweet_id}")
            else:
                error_msg = result.get('message', 'å‘å¸ƒå¤±è´¥') if result else 'å‘å¸ƒå¤±è´¥'
                publish_result["error"] = error_msg
                logger.error(f"âŒ ä»Šæ—¥ç§‘æŠ€å¤´æ¡å‘å¸ƒå¤±è´¥: {error_msg}")
            
            # è®°å½•å‘å¸ƒæ—¥å¿—
            await self._log_publish_result(publish_result)
            return publish_result
            
        except Exception as e:
            logger.error(f"âŒ å‘å¸ƒä»Šæ—¥ç§‘æŠ€å¤´æ¡å‡ºé”™: {e}")
            return {
                "task": "morning_headlines",
                "time": datetime.now(timezone.utc).isoformat(),
                "success": False,
                "error": str(e)
            }
    
    async def publish_ai_thread(self) -> Dict[str, Any]:
        """12:00 å‘å¸ƒAI+ä¼ ç»Ÿæ™ºæ…§çº¿ç¨‹"""
        try:
            logger.info("ğŸ§  å¼€å§‹å‘å¸ƒAI+ä¼ ç»Ÿæ™ºæ…§çº¿ç¨‹")
            current_time = datetime.now(timezone.utc)
            
            # ç”Ÿæˆæ™ºæ…§çº¿ç¨‹å†…å®¹ï¼ˆè½®æ¢AIå’Œä¸­åŒ»ç§‘æŠ€ï¼‰
            thread_content = await self.content_generator.generate_wisdom_ai_thread()
            
            # åˆ›å»ºçº¿ç¨‹
            thread_result = await self.thread_creator.create_thread(thread_content)
            
            publish_result = {
                "task": "ai_thread",
                "time": current_time.isoformat(),
                "success": thread_result.success,
                "tweet_ids": thread_result.tweet_ids,
                "thread_url": thread_result.thread_url,
                "error": thread_result.error_message
            }
            
            if thread_result.success:
                logger.info(f"âœ… å¯æŒç»­AIçº¿ç¨‹å‘å¸ƒæˆåŠŸ: {len(thread_result.tweet_ids)}æ¡æ¨æ–‡")
            else:
                logger.error(f"âŒ å¯æŒç»­AIçº¿ç¨‹å‘å¸ƒå¤±è´¥: {thread_result.error_message}")
            
            # è®°å½•å‘å¸ƒæ—¥å¿—
            await self._log_publish_result(publish_result)
            return publish_result
            
        except Exception as e:
            logger.error(f"âŒ å‘å¸ƒå¯æŒç»­AIçº¿ç¨‹å‡ºé”™: {e}")
            return {
                "task": "ai_thread",
                "time": datetime.now(timezone.utc).isoformat(),
                "success": False,
                "error": str(e)
            }
    
    async def publish_tcm_tech_focus(self) -> Dict[str, Any]:
        """14:00 å‘å¸ƒä¸­åŒ»ç§‘æŠ€ä¸“é¢˜"""
        try:
            logger.info("ğŸ¥ å¼€å§‹å‘å¸ƒä¸­åŒ»ç§‘æŠ€ä¸“é¢˜")
            current_time = datetime.now(timezone.utc)
            
            # ç”Ÿæˆä¸­åŒ»ç§‘æŠ€ä¸“é¢˜å†…å®¹
            tcm_content = await self.content_generator.generate_daily_tcm_tech_content()
            
            # å‘å¸ƒæ¨æ–‡
            result = await post_tweet(tcm_content)
            
            publish_result = {
                "task": "tcm_tech_focus",
                "time": current_time.isoformat(),
                "success": False,
                "content": tcm_content,
                "tweet_id": None,
                "error": None
            }
            
            if result and result.get('success'):
                tweet_id = result.get('data', {}).get('id')
                publish_result.update({
                    "success": True,
                    "tweet_id": tweet_id,
                })
                logger.info(f"âœ… ä¸­åŒ»ç§‘æŠ€ä¸“é¢˜å‘å¸ƒæˆåŠŸ: {tweet_id}")
            else:
                error_msg = result.get('message', 'å‘å¸ƒå¤±è´¥') if result else 'å‘å¸ƒå¤±è´¥'
                publish_result["error"] = error_msg
                logger.error(f"âŒ ä¸­åŒ»ç§‘æŠ€ä¸“é¢˜å‘å¸ƒå¤±è´¥: {error_msg}")
            
            # è®°å½•å‘å¸ƒæ—¥å¿—
            await self._log_publish_result(publish_result)
            return publish_result
            
        except Exception as e:
            logger.error(f"âŒ å‘å¸ƒä¸­åŒ»ç§‘æŠ€ä¸“é¢˜å‡ºé”™: {e}")
            return {
                "task": "tcm_tech_focus",
                "time": datetime.now(timezone.utc).isoformat(),
                "success": False,
                "error": str(e)
            }
    
    async def publish_curated_retweet(self) -> Dict[str, Any]:
        """16:00 å‘å¸ƒç²¾é€‰è½¬å‘"""
        try:
            logger.info("ğŸ”„ å¼€å§‹å‘å¸ƒç²¾é€‰è½¬å‘")
            current_time = datetime.now(timezone.utc)
            
            # å¯»æ‰¾è½¬å‘ç›®æ ‡
            retweet_target = await self.content_generator.find_retweet_target()
            
            publish_result = {
                "task": "curated_retweet",
                "time": current_time.isoformat(),
                "success": False,
                "original_tweet_id": None,
                "quote_tweet_id": None,
                "comment": None,
                "error": None
            }
            
            if not retweet_target:
                publish_result["error"] = "æœªæ‰¾åˆ°åˆé€‚çš„è½¬å‘ç›®æ ‡"
                logger.warning("âš ï¸ æœªæ‰¾åˆ°åˆé€‚çš„è½¬å‘ç›®æ ‡")
                await self._log_publish_result(publish_result)
                return publish_result
            
            # æ‰§è¡Œå¼•ç”¨è½¬å‘
            quote_result = await quote_tweet(
                retweet_target["tweet_id"],
                retweet_target["comment"]
            )
            
            publish_result.update({
                "original_tweet_id": retweet_target["tweet_id"],
                "comment": retweet_target["comment"]
            })
            
            if quote_result and quote_result.get('success'):
                quote_tweet_id = quote_result.get('data', {}).get('id')
                publish_result.update({
                    "success": True,
                    "quote_tweet_id": quote_tweet_id
                })
                logger.info(f"âœ… ç²¾é€‰è½¬å‘å‘å¸ƒæˆåŠŸ: {quote_tweet_id}")
            else:
                error_msg = quote_result.get('message', 'è½¬å‘å¤±è´¥') if quote_result else 'è½¬å‘å¤±è´¥'
                publish_result["error"] = error_msg
                logger.error(f"âŒ ç²¾é€‰è½¬å‘å¤±è´¥: {error_msg}")
            
            # è®°å½•å‘å¸ƒæ—¥å¿—
            await self._log_publish_result(publish_result)
            return publish_result
            
        except Exception as e:
            logger.error(f"âŒ å‘å¸ƒç²¾é€‰è½¬å‘å‡ºé”™: {e}")
            return {
                "task": "curated_retweet",
                "time": datetime.now(timezone.utc).isoformat(),
                "success": False,
                "error": str(e)
            }
    
    async def publish_weekly_recap(self) -> Dict[str, Any]:
        """20:00 å‘å¸ƒå‘¨æŠ¥ï¼ˆä»…å‘¨æ—¥ï¼‰"""
        try:
            current_time = datetime.now(timezone.utc)
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºå‘¨æ—¥
            if current_time.weekday() != 6:  # 0=Monday, 6=Sunday
                logger.info("ğŸ“Š ä»Šå¤©ä¸æ˜¯å‘¨æ—¥ï¼Œè·³è¿‡å‘¨æŠ¥å‘å¸ƒ")
                return {
                    "task": "weekly_recap",
                    "time": current_time.isoformat(),
                    "success": True,
                    "skipped": True,
                    "reason": "ä»Šå¤©ä¸æ˜¯å‘¨æ—¥"
                }
            
            logger.info("ğŸ“Š å¼€å§‹å‘å¸ƒæœ¬å‘¨ç§‘æŠ€è¶‹åŠ¿å›é¡¾")
            
            # ç”Ÿæˆå‘¨æŠ¥å†…å®¹
            recap_content = await self.content_generator.generate_weekly_recap()
            
            # å‘å¸ƒæ¨æ–‡
            result = await post_tweet(recap_content)
            
            publish_result = {
                "task": "weekly_recap",
                "time": current_time.isoformat(),
                "success": False,
                "content": recap_content,
                "tweet_id": None,
                "error": None
            }
            
            if result and result.get('success'):
                tweet_id = result.get('data', {}).get('id')
                publish_result.update({
                    "success": True,
                    "tweet_id": tweet_id
                })
                logger.info(f"âœ… æœ¬å‘¨å›é¡¾å‘å¸ƒæˆåŠŸ: {tweet_id}")
            else:
                error_msg = result.get('message', 'å‘å¸ƒå¤±è´¥') if result else 'å‘å¸ƒå¤±è´¥'
                publish_result["error"] = error_msg
                logger.error(f"âŒ æœ¬å‘¨å›é¡¾å‘å¸ƒå¤±è´¥: {error_msg}")
            
            # è®°å½•å‘å¸ƒæ—¥å¿—
            await self._log_publish_result(publish_result)
            return publish_result
            
        except Exception as e:
            logger.error(f"âŒ å‘å¸ƒæœ¬å‘¨å›é¡¾å‡ºé”™: {e}")
            return {
                "task": "weekly_recap",
                "time": datetime.now(timezone.utc).isoformat(),
                "success": False,
                "error": str(e)
            }
    
    async def _log_publish_result(self, result: Dict[str, Any]):
        """è®°å½•å‘å¸ƒç»“æœæ—¥å¿—"""
        try:
            current_date = datetime.now(timezone.utc).strftime("%Y-%m-%d")
            log_file = self.log_dir / f"publish_log_{current_date}.json"
            
            import json
            
            # è¯»å–ç°æœ‰æ—¥å¿—
            existing_logs = []
            if log_file.exists():
                try:
                    with open(log_file, 'r', encoding='utf-8') as f:
                        existing_logs = json.load(f)
                except json.JSONDecodeError:
                    existing_logs = []
            
            # æ·»åŠ æ–°æ—¥å¿—
            existing_logs.append(result)
            
            # å†™å…¥æ—¥å¿—æ–‡ä»¶
            with open(log_file, 'w', encoding='utf-8') as f:
                json.dump(existing_logs, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            logger.warning(f"âš ï¸ è®°å½•å‘å¸ƒæ—¥å¿—å¤±è´¥: {e}")
    
    async def run_daily_schedule(self):
        """è¿è¡Œä¸€å¤©çš„å®Œæ•´å‘å¸ƒè®¡åˆ’ï¼ˆæµ‹è¯•ç”¨ï¼‰"""
        logger.info("ğŸš€ å¼€å§‹è¿è¡Œæ¯æ—¥å‘å¸ƒè®¡åˆ’")
        results = []
        
        # æ¨¡æ‹Ÿä¸€å¤©çš„å‘å¸ƒä»»åŠ¡
        tasks = [
            ("08:00", self.publish_morning_headlines),
            ("12:00", self.publish_ai_thread),
            ("14:00", self.publish_tcm_tech_focus),
            ("16:00", self.publish_curated_retweet),
            ("20:00", self.publish_weekly_recap)
        ]
        
        for time_str, task_func in tasks:
            logger.info(f"â° æ‰§è¡Œ {time_str} ä»»åŠ¡: {task_func.__name__}")
            result = await task_func()
            results.append(result)
            
            # ä»»åŠ¡é—´éš”30ç§’ï¼ˆæµ‹è¯•æ—¶ä½¿ç”¨ï¼‰
            await asyncio.sleep(30)
        
        # è¾“å‡ºæ€»ç»“
        successful_tasks = [r for r in results if r.get('success') and not r.get('skipped')]
        failed_tasks = [r for r in results if not r.get('success') and not r.get('skipped')]
        skipped_tasks = [r for r in results if r.get('skipped')]
        
        logger.info(f"ğŸ“ˆ æ¯æ—¥å‘å¸ƒå®Œæˆç»Ÿè®¡:")
        logger.info(f"  âœ… æˆåŠŸ: {len(successful_tasks)}ä¸ªä»»åŠ¡")
        logger.info(f"  âŒ å¤±è´¥: {len(failed_tasks)}ä¸ªä»»åŠ¡")
        logger.info(f"  â­ï¸  è·³è¿‡: {len(skipped_tasks)}ä¸ªä»»åŠ¡")
        
        return {
            "total_tasks": len(results),
            "successful": len(successful_tasks),
            "failed": len(failed_tasks),
            "skipped": len(skipped_tasks),
            "results": results
        }
    
    async def get_publish_status(self, date: Optional[str] = None) -> Dict[str, Any]:
        """è·å–å‘å¸ƒçŠ¶æ€"""
        try:
            if not date:
                date = datetime.now(timezone.utc).strftime("%Y-%m-%d")
            
            log_file = self.log_dir / f"publish_log_{date}.json"
            
            if not log_file.exists():
                return {
                    "date": date,
                    "status": "no_logs",
                    "tasks": []
                }
            
            import json
            with open(log_file, 'r', encoding='utf-8') as f:
                logs = json.load(f)
            
            return {
                "date": date,
                "status": "has_logs",
                "total_tasks": len(logs),
                "successful_tasks": len([l for l in logs if l.get('success')]),
                "tasks": logs
            }
            
        except Exception as e:
            logger.error(f"âŒ è·å–å‘å¸ƒçŠ¶æ€å‡ºé”™: {e}")
            return {
                "error": str(e)
            }


if __name__ == "__main__":
    # æµ‹è¯•æ¯æ—¥å‘å¸ƒå™¨
    async def test_daily_publisher():
        publisher = DailyTechPublisher()
        
        print("=== æ¯æ—¥å‘å¸ƒå™¨åŠŸèƒ½æµ‹è¯• ===\n")
        
        # æµ‹è¯•å†…å®¹ç”Ÿæˆï¼ˆä¸å®é™…å‘å¸ƒï¼‰
        print("1. æµ‹è¯•ä»Šæ—¥ç§‘æŠ€å¤´æ¡ç”Ÿæˆ:")
        headlines = await publisher.content_generator.generate_daily_headlines()
        print(f"   å†…å®¹: {headlines}")
        print(f"   å­—æ•°: {len(headlines)}\n")
        
        print("2. æµ‹è¯•å¯æŒç»­AIçº¿ç¨‹ç”Ÿæˆ:")
        ai_content = await publisher.content_generator.generate_sustainable_ai_thread()
        for i, content in enumerate(ai_content, 1):
            print(f"   {i}. {content[:60]}... (å­—æ•°: {len(content)})")
        print()
        
        print("3. æµ‹è¯•è½¬å‘ç›®æ ‡æœç´¢:")
        retweet_target = await publisher.content_generator.find_retweet_target()
        if retweet_target:
            print(f"   ç›®æ ‡: {retweet_target['original_text']}")
            print(f"   è¯„è®º: {retweet_target['comment']}")
        else:
            print("   æœªæ‰¾åˆ°è½¬å‘ç›®æ ‡")
        print()
        
        print("4. æµ‹è¯•å‘¨æŠ¥ç”Ÿæˆ:")
        weekly_recap = await publisher.content_generator.generate_weekly_recap()
        print(f"   å†…å®¹: {weekly_recap}")
        print(f"   å­—æ•°: {len(weekly_recap)}\n")
        
        print("æ³¨æ„: å®é™…è¿è¡Œæ—¶ä¼šè°ƒç”¨Twitter APIå‘å¸ƒå†…å®¹")
        print("ä½¿ç”¨ python run_scheduler.py å¯åŠ¨å®šæ—¶å‘å¸ƒ")
    
    asyncio.run(test_daily_publisher())