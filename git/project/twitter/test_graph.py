#!/usr/bin/env python3
"""æµ‹è¯•graphç›´æ¥è°ƒç”¨"""

import asyncio
import sys
from pathlib import Path
from dotenv import load_dotenv

load_dotenv()

# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root / "src"))

from react_agent.context import Context
from react_agent.graph import graph
from react_agent.state import InputState
from langchain_core.messages import HumanMessage


async def test_direct_graph_call():
    """ç›´æ¥æµ‹è¯•graphè°ƒç”¨"""
    try:
        print("ğŸ§ª æµ‹è¯•ç›´æ¥è°ƒç”¨graph...")
        
        # åˆ›å»ºç®€å•çš„è¾“å…¥
        input_state = InputState(
            messages=[HumanMessage(content="Hello, can you search for AI trends?")]
        )
        
        print(f"ğŸ“ è¾“å…¥çŠ¶æ€: {input_state}")
        
        # åˆ›å»ºcontexté…ç½®
        context = Context()
        print(f"ğŸ”§ Contextåˆ›å»º: model={context.model}")
        
        # ç›´æ¥è°ƒç”¨graph
        result = await graph.ainvoke(
            input_state,
            config={
                "recursion_limit": 10,
                "configurable": {
                    "model": context.model,
                    "system_prompt": context.system_prompt,
                    "max_search_results": context.max_search_results,
                    "twitter_user_id": context.twitter_user_id
                }
            }
        )
        
        print(f"âœ… è°ƒç”¨æˆåŠŸ!")
        print(f"ğŸ“¤ ç»“æœ: {result}")
        
        if result and result.get("messages"):
            last_message = result["messages"][-1]
            print(f"ğŸ¯ æœ€åæ¶ˆæ¯: {last_message.content[:200]}...")
        
    except Exception as e:
        print(f"âŒ è°ƒç”¨å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(test_direct_graph_call())