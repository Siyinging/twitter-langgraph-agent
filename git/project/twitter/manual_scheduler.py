#!/usr/bin/env python3
"""æ‰‹åŠ¨Twitterè°ƒåº¦å™¨ - ä¸ä¾èµ–å¤æ‚çš„Graphè°ƒç”¨

è¿™ä¸ªç®€åŒ–ç‰ˆæœ¬ç›´æ¥è°ƒç”¨å·¥å…·å‡½æ•°ï¼Œé¿å…Graphé…ç½®é—®é¢˜
"""

import asyncio
import logging
import os
from datetime import datetime, timezone
from typing import Dict, Any
from pathlib import Path
import sys

from dotenv import load_dotenv
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.interval import IntervalTrigger
from apscheduler.triggers.cron import CronTrigger

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root / "src"))

# ç°åœ¨å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from react_agent.tools import (
    _get_all_mcp_tools, 
    advanced_search_twitter,
    get_trends,
    post_tweet
)
from react_agent.daily_publisher import DailyTechPublisher
from langchain_tavily import TavilySearch
from react_agent.data_collector import TechDataCollector
from react_agent.tech_visualizer import TechVisualizer
from react_agent.enhanced_visualizer import EnhancedVisualizer
from react_agent.image_generator import ImageGenerator


class ManualTwitterScheduler:
    """æ‰‹åŠ¨Twitterè°ƒåº¦å™¨ - ç›´æ¥è°ƒç”¨å·¥å…·"""
    
    def __init__(self, interval_hours: int = 3):
        self.interval_hours = interval_hours
        self.scheduler = AsyncIOScheduler()
        
        # åˆå§‹åŒ–æ•°æ®æ”¶é›†å™¨å’Œå¯è§†åŒ–å™¨
        self.data_collector = TechDataCollector()
        self.visualizer = TechVisualizer()
        self.enhanced_visualizer = EnhancedVisualizer()
        self.image_generator = ImageGenerator()
        
        # åˆå§‹åŒ–æ¯æ—¥å‘å¸ƒå™¨
        self.daily_publisher = DailyTechPublisher()
        
        # é…ç½®æ—¥å¿—
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)
    
    async def search_web(self, query: str) -> str:
        """ä½¿ç”¨Tavilyæœç´¢ç½‘ç»œ"""
        try:
            tavily = TavilySearch(max_results=5)
            results = await tavily.ainvoke({"query": query})
            
            # æå–æœ‰ç”¨ä¿¡æ¯
            content = []
            for result in results.get('results', [])[:3]:  # å–å‰3ä¸ªç»“æœ
                if isinstance(result, dict):
                    title = result.get('title', '')
                    snippet = result.get('content', result.get('snippet', ''))
                    if title and snippet:
                        content.append(f"â€¢ {title}: {snippet[:100]}...")
            
            return "\n".join(content) if content else str(results)[:500]
        except Exception as e:
            self.logger.error(f"Web search failed: {e}")
            return f"Search error: {str(e)}"
    
    async def execute_trend_analysis_task(self):
        """æ‰§è¡Œè¶‹åŠ¿åˆ†æä»»åŠ¡"""
        try:
            self.logger.info("ğŸš€ å¼€å§‹æ‰§è¡Œè¶‹åŠ¿åˆ†æä»»åŠ¡")
            
            # 1. æœç´¢AIå’Œç§‘æŠ€è¶‹åŠ¿
            web_results = await self.search_web("AI technology trends 2024 latest news")
            
            # 2. å°è¯•è·å–Twitterè¶‹åŠ¿ï¼ˆå¦‚æœMCPå¯ç”¨ï¼‰
            twitter_trends = ""
            try:
                tools = await _get_all_mcp_tools()
                if "get_trends" in tools:
                    trends_result = await tools["get_trends"].ainvoke({"woeid": 1})
                    twitter_trends = f"Twitter trends: {str(trends_result)[:200]}..."
                else:
                    twitter_trends = "Twitter MCP unavailable"
            except Exception as e:
                twitter_trends = f"Twitter trends error: {str(e)}"
                self.logger.warning(f"Twitter trends failed: {e}")
            
            # 3. ç”ŸæˆåŸºäºè¶‹åŠ¿çš„æ¨æ–‡å†…å®¹
            current_time = datetime.now(timezone.utc).strftime("%Y-%m-%d %H:%M UTC")
            
            tweet_content = self.generate_tweet_from_trends(web_results, twitter_trends, current_time)
            
            # 4. å°è¯•å‘å¸ƒæ¨æ–‡ï¼ˆå¦‚æœMCPå¯ç”¨ï¼‰
            try:
                tools = await _get_all_mcp_tools()
                if "post_tweet" in tools:
                    post_result = await tools["post_tweet"].ainvoke({
                        "text": tweet_content,
                        "user_id": "e634c89a-a63a-40fe-af3b-b9d96de0b97a",
                        "media_inputs": []
                    })
                    self.logger.info(f"âœ… æ¨æ–‡å‘å¸ƒæˆåŠŸ: {post_result}")
                else:
                    self.logger.info(f"ğŸ“ æ¨æ–‡å†…å®¹ (MCPä¸å¯ç”¨): {tweet_content}")
            except Exception as e:
                self.logger.error(f"æ¨æ–‡å‘å¸ƒå¤±è´¥: {e}")
                self.logger.info(f"ğŸ“ æ¨æ–‡å†…å®¹: {tweet_content}")
            
            self.logger.info("âœ… è¶‹åŠ¿åˆ†æä»»åŠ¡å®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"âŒ è¶‹åŠ¿åˆ†æä»»åŠ¡å¤±è´¥: {str(e)}")
    
    def generate_tweet_from_trends(self, web_trends: str, twitter_trends: str, timestamp: str) -> str:
        """åŸºäºè¶‹åŠ¿ç”Ÿæˆæ¨æ–‡å†…å®¹"""
        # ç®€å•çš„æ¨æ–‡ç”Ÿæˆé€»è¾‘
        templates = [
            "ğŸ¤– AIæ­£åœ¨å¿«é€Ÿå‘å±•ï¼æ ¹æ®æœ€æ–°è¶‹åŠ¿åˆ†æï¼ŒæŠ€æœ¯åˆ›æ–°æŒç»­åŠ é€Ÿã€‚å€¼å¾—å…³æ³¨çš„å‘å±•æ–¹å‘åŒ…æ‹¬æœºå™¨å­¦ä¹ ã€è‡ªåŠ¨åŒ–å’Œæ™ºèƒ½ç³»ç»Ÿã€‚ #{timestamp} #AI #Tech",
            "ğŸ“Š ç§‘æŠ€è¶‹åŠ¿è§‚å¯Ÿï¼šäººå·¥æ™ºèƒ½æŠ€æœ¯æ­£åœ¨é‡å¡‘å„è¡Œå„ä¸šã€‚ä»æ•°æ®åˆ†æåˆ°å†…å®¹åˆ›ä½œï¼ŒAIçš„åº”ç”¨åœºæ™¯è¶Šæ¥è¶Šå¹¿æ³›ã€‚ #{timestamp} #TechTrends #Innovation", 
            "âš¡ æœ€æ–°ç§‘æŠ€åŠ¨æ€ï¼šAIæŠ€æœ¯å‘å±•è¿…çŒ›ï¼Œä¸ºå„è¡Œä¸šå¸¦æ¥æ–°æœºé‡ã€‚æŒç»­å…³æ³¨æŠ€æœ¯å˜é©ï¼Œæ‹¥æŠ±æ•°å­—åŒ–æœªæ¥ï¼ #{timestamp} #ArtificialIntelligence #Future",
            "ğŸš€ æŠ€æœ¯å‰æ²¿è§‚å¯Ÿï¼šäººå·¥æ™ºèƒ½ã€æœºå™¨å­¦ä¹ ã€æ•°æ®ç§‘å­¦ç­‰é¢†åŸŸæŒç»­åˆ›æ–°ã€‚ç§‘æŠ€æ”¹å˜ç”Ÿæ´»ï¼Œåˆ›æ–°é©±åŠ¨æœªæ¥ï¼ #{timestamp} #TechNews #AI"
        ]
        
        # é€‰æ‹©ä¸€ä¸ªæ¨¡æ¿å¹¶å¡«å……æ—¶é—´æˆ³
        import random
        template = random.choice(templates)
        tweet = template.replace("#{timestamp}", timestamp.split()[0])  # åªç”¨æ—¥æœŸéƒ¨åˆ†
        
        # ç¡®ä¿æ¨æ–‡é•¿åº¦ä¸è¶…è¿‡280å­—ç¬¦
        if len(tweet) > 280:
            tweet = tweet[:277] + "..."
        
        return tweet
    
    async def execute_engagement_check_task(self):
        """æ‰§è¡Œäº’åŠ¨æ£€æŸ¥ä»»åŠ¡"""
        try:
            self.logger.info("ğŸš€ å¼€å§‹æ‰§è¡Œäº’åŠ¨æ£€æŸ¥ä»»åŠ¡")
            
            # å°è¯•æ£€æŸ¥äº’åŠ¨ï¼ˆå¦‚æœMCPå¯ç”¨ï¼‰
            try:
                tools = await _get_all_mcp_tools()
                if "advanced_search_twitter" in tools:
                    # æœç´¢è‡ªå·±çš„æœ€è¿‘æ¨æ–‡
                    search_result = await tools["advanced_search_twitter"].ainvoke({
                        "llm_text": "from:myaccount recent interactions"
                    })
                    self.logger.info(f"ğŸ“Š äº’åŠ¨æ£€æŸ¥ç»“æœ: {str(search_result)[:200]}...")
                else:
                    self.logger.info("ğŸ“Š Twitteræœç´¢MCPä¸å¯ç”¨ï¼Œè·³è¿‡äº’åŠ¨æ£€æŸ¥")
            except Exception as e:
                self.logger.warning(f"äº’åŠ¨æ£€æŸ¥å¤±è´¥: {e}")
            
            self.logger.info("âœ… äº’åŠ¨æ£€æŸ¥ä»»åŠ¡å®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"âŒ äº’åŠ¨æ£€æŸ¥ä»»åŠ¡å¤±è´¥: {str(e)}")
    
    async def execute_image_tweet_task(self):
        """æ‰§è¡Œå›¾ç‰‡æ¨æ–‡ä»»åŠ¡"""
        try:
            self.logger.info("ğŸ“¸ å¼€å§‹æ‰§è¡Œå›¾ç‰‡æ¨æ–‡ä»»åŠ¡")
            
            # 1. æ”¶é›†æœ€æ–°æ•°æ®
            self.logger.info("ğŸ“Š æ”¶é›†ç§‘æŠ€æ•°æ®...")
            trends_data = await self.data_collector.collect_web_trends()
            
            # 2. ç”ŸæˆTwitterä¼˜åŒ–çš„å›¾ç‰‡
            self.logger.info("ğŸ¨ ç”ŸæˆTwitterå›¾ç‰‡...")
            image_results = await self.enhanced_visualizer.batch_generate_twitter_images(trends_data)
            
            if image_results:
                self.logger.info(f"âœ… æˆåŠŸç”Ÿæˆ {len(image_results)} å¼ å›¾ç‰‡")
                
                # 3. éšæœºé€‰æ‹©ä¸€å¼ å›¾ç‰‡å‘å¸ƒ
                import random
                selected_image, tweet_text = random.choice(image_results)
                
                self.logger.info(f"ğŸ“± å‡†å¤‡å‘å¸ƒå›¾ç‰‡æ¨æ–‡: {Path(selected_image).name}")
                
                # 4. å°è¯•å‘å¸ƒå¸¦å›¾ç‰‡çš„æ¨æ–‡
                try:
                    tools = await _get_all_mcp_tools()
                    if "post_tweet" in tools:
                        # è¯»å–å›¾ç‰‡æ–‡ä»¶
                        import base64
                        with open(selected_image, 'rb') as img_file:
                            img_data = base64.b64encode(img_file.read()).decode('utf-8')
                        
                        # å‘å¸ƒå¸¦å›¾ç‰‡çš„æ¨æ–‡
                        post_result = await tools["post_tweet"].ainvoke({
                            "text": tweet_text,
                            "user_id": "e634c89a-a63a-40fe-af3b-b9d96de0b97a",
                            "media_inputs": [{"data": img_data, "media_type": "image/png"}]
                        })
                        self.logger.info(f"ğŸ“± å›¾ç‰‡æ¨æ–‡å‘å¸ƒæˆåŠŸ: {post_result}")
                    else:
                        self.logger.info(f"ğŸ“ å›¾ç‰‡æ¨æ–‡å†…å®¹ (MCPä¸å¯ç”¨):")
                        self.logger.info(f"   ğŸ“· å›¾ç‰‡: {selected_image}")
                        self.logger.info(f"   ğŸ“ æ–‡æœ¬: {tweet_text}")
                        
                except Exception as e:
                    self.logger.error(f"å›¾ç‰‡æ¨æ–‡å‘å¸ƒå¤±è´¥: {e}")
                    self.logger.info(f"ğŸ“ å›¾ç‰‡æ¨æ–‡å†…å®¹:")
                    self.logger.info(f"   ğŸ“· å›¾ç‰‡: {selected_image}")
                    self.logger.info(f"   ğŸ“ æ–‡æœ¬: {tweet_text}")
                
                # 5. è®°å½•ç”Ÿæˆçš„å›¾ç‰‡ä¿¡æ¯
                for image_path, text in image_results:
                    image_info = self.image_generator.get_image_info(image_path)
                    self.logger.info(f"ğŸ“Š å›¾ç‰‡ä¿¡æ¯: {image_info}")
                    
            else:
                self.logger.warning("âš ï¸ æœªèƒ½ç”Ÿæˆä»»ä½•å›¾ç‰‡")
            
            self.logger.info("âœ… å›¾ç‰‡æ¨æ–‡ä»»åŠ¡å®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"âŒ å›¾ç‰‡æ¨æ–‡ä»»åŠ¡å¤±è´¥: {str(e)}")
    
    async def execute_data_visualization_task(self):
        """æ‰§è¡Œæ•°æ®å¯è§†åŒ–ä»»åŠ¡"""
        try:
            self.logger.info("ğŸ¨ å¼€å§‹æ‰§è¡Œæ•°æ®å¯è§†åŒ–ä»»åŠ¡")
            
            # 1. æ”¶é›†æœ€æ–°çš„ç§‘æŠ€æ•°æ®
            self.logger.info("ğŸ“Š æ”¶é›†ç§‘æŠ€è¶‹åŠ¿æ•°æ®...")
            trends_data = await self.data_collector.collect_web_trends()
            
            # 2. ç”Ÿæˆå…³é”®è¯æŒ‡æ ‡
            self.logger.info("ğŸ” åˆ†æå…³é”®è¯æŒ‡æ ‡...")
            metrics_data = await self.data_collector.collect_keyword_metrics()
            
            # 3. ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
            self.logger.info("ğŸ¨ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
            chart_files = await self.visualizer.generate_all_charts(trends_data)
            
            if chart_files:
                self.logger.info(f"âœ… æˆåŠŸç”Ÿæˆ {len(chart_files)} ä¸ªå›¾è¡¨:")
                for i, chart_file in enumerate(chart_files, 1):
                    filename = Path(chart_file).name
                    self.logger.info(f"  {i}. {filename}")
                
                # 4. ç”Ÿæˆå…³äºå›¾è¡¨çš„æ¨æ–‡å†…å®¹
                tweet_content = self.generate_chart_tweet(trends_data, len(chart_files))
                
                # 5. å°è¯•å‘å¸ƒåŒ…å«å›¾è¡¨ä¿¡æ¯çš„æ¨æ–‡
                try:
                    tools = await _get_all_mcp_tools()
                    if "post_tweet" in tools:
                        post_result = await tools["post_tweet"].ainvoke({
                            "text": tweet_content,
                            "user_id": "e634c89a-a63a-40fe-af3b-b9d96de0b97a",
                            "media_inputs": []
                        })
                        self.logger.info(f"ğŸ“± å›¾è¡¨åˆ†ææ¨æ–‡å‘å¸ƒæˆåŠŸ: {post_result}")
                    else:
                        self.logger.info(f"ğŸ“ å›¾è¡¨åˆ†ææ¨æ–‡å†…å®¹ (MCPä¸å¯ç”¨): {tweet_content}")
                except Exception as e:
                    self.logger.error(f"æ¨æ–‡å‘å¸ƒå¤±è´¥: {e}")
                    self.logger.info(f"ğŸ“ å›¾è¡¨åˆ†ææ¨æ–‡å†…å®¹: {tweet_content}")
            else:
                self.logger.warning("âš ï¸ æœªèƒ½ç”Ÿæˆä»»ä½•å›¾è¡¨")
            
            self.logger.info("âœ… æ•°æ®å¯è§†åŒ–ä»»åŠ¡å®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"âŒ æ•°æ®å¯è§†åŒ–ä»»åŠ¡å¤±è´¥: {str(e)}")
    
    def generate_chart_tweet(self, data: Dict[str, Any], chart_count: int) -> str:
        """ç”Ÿæˆå…³äºå›¾è¡¨åˆ†æçš„æ¨æ–‡å†…å®¹"""
        keywords_data = data.get("keywords_count", {})
        top_keyword = max(keywords_data, key=keywords_data.get) if keywords_data else "AI"
        
        templates = [
            f"ğŸ“Š åˆšåˆšå®Œæˆç§‘æŠ€æ•°æ®åˆ†æï¼Œç”Ÿæˆäº†{chart_count}ä¸ªå¯è§†åŒ–å›¾è¡¨ï¼å½“å‰æœ€çƒ­è¯é¢˜ï¼š{top_keyword}ã€‚æ•°æ®æ˜¾ç¤ºAIæŠ€æœ¯æŒç»­å‡æ¸©ï¼Œå€¼å¾—å…³æ³¨ï¼#DataVisualization #TechTrends #ç§‘æŠ€åˆ†æ",
            f"ğŸ¯ æœ€æ–°ç§‘æŠ€è¶‹åŠ¿å›¾è¡¨æ–°é²œå‡ºç‚‰ï¼é€šè¿‡æ•°æ®åˆ†æå‘ç°ï¼Œ{top_keyword}é¢†åŸŸçƒ­åº¦å±…é«˜ä¸ä¸‹ã€‚ç§‘æŠ€å‘å±•æ—¥æ–°æœˆå¼‚ï¼Œè®©æˆ‘ä»¬ç”¨æ•°æ®çœ‹æœªæ¥ï¼#TechAnalytics #DataScience #AIè¶‹åŠ¿",
            f"ğŸ“ˆ ç”¨æ•°æ®è¯´è¯ï¼ä»Šæ—¥ç§‘æŠ€çƒ­ç‚¹åˆ†æå®Œæˆï¼Œç”Ÿæˆ{chart_count}ä¸ªä¸“ä¸šå›¾è¡¨ã€‚{top_keyword}è¯é¢˜è®¨è®ºåº¦æœ€é«˜ï¼Œç§‘æŠ€åˆ›æ–°æ­¥ä¼åŠ å¿«ï¼#DataDriven #Technology #Innovation",
            f"ğŸ”¥ ç§‘æŠ€æ•°æ®å®æ—¶ç›‘æ§æ›´æ–°ï¼å½“å‰{top_keyword}ç›¸å…³è¯é¢˜æœ€æ´»è·ƒï¼Œé€šè¿‡å¯è§†åŒ–åˆ†æçœ‹åˆ°äº†æœ‰è¶£çš„è¶‹åŠ¿ã€‚æŠ€æœ¯æ”¹å˜ä¸–ç•Œï¼#RealTimeData #TechMonitoring #Future"
        ]
        
        import random
        template = random.choice(templates)
        
        # ç¡®ä¿æ¨æ–‡é•¿åº¦ä¸è¶…è¿‡280å­—ç¬¦
        if len(template) > 280:
            template = template[:277] + "..."
        
        return template
    
    def add_scheduled_jobs(self):
        """æ·»åŠ å®šæ—¶ä»»åŠ¡"""
        # === æ¯æ—¥ç§‘æŠ€å†…å®¹å‘å¸ƒä»»åŠ¡ï¼ˆæ–°å¢ï¼‰ ===
        
        # 06:30 - åˆ›å»ºå†…å®¹è‰ç¨¿ä¾›å®¡æ ¸
        self.scheduler.add_job(
            self.daily_publisher.create_content_drafts_for_review,
            trigger=CronTrigger(hour=6, minute=30),
            id="create_drafts_job",
            name="åˆ›å»ºæ¯æ—¥å†…å®¹è‰ç¨¿",
            replace_existing=True,
            max_instances=1
        )
        
        # 07:45 - å‘å¸ƒå·²å®¡æ ¸é€šè¿‡çš„å†…å®¹ï¼ˆæ›¿ä»£åŸæœ‰å®šæ—¶å‘å¸ƒï¼‰
        self.scheduler.add_job(
            self.daily_publisher.publish_approved_content,
            trigger=CronTrigger(hour=7, minute=45),
            id="publish_approved_job",
            name="å‘å¸ƒå·²å®¡æ ¸å†…å®¹",
            replace_existing=True,
            max_instances=1
        )
        
        # 08:00 - ä»Šæ—¥ç§‘æŠ€å¤´æ¡ï¼ˆèåˆä¸­åŒ»ç§‘æŠ€ï¼‰
        self.scheduler.add_job(
            self.daily_publisher.publish_morning_headlines,
            trigger=CronTrigger(hour=8, minute=0),
            id="daily_headlines_job",
            name="ä»Šæ—¥ç§‘æŠ€å¤´æ¡å‘å¸ƒï¼ˆå«ä¸­åŒ»ç§‘æŠ€ï¼‰",
            replace_existing=True,
            max_instances=1
        )
        
        # 12:00 - AI+ä¼ ç»Ÿæ™ºæ…§çº¿ç¨‹
        self.scheduler.add_job(
            self.daily_publisher.publish_ai_thread,
            trigger=CronTrigger(hour=12, minute=0),
            id="ai_wisdom_thread_job",
            name="AI+ä¼ ç»Ÿæ™ºæ…§çº¿ç¨‹å‘å¸ƒ",
            replace_existing=True,
            max_instances=1
        )
        
        # 14:00 - ä¸­åŒ»ç§‘æŠ€ä¸“é¢˜
        self.scheduler.add_job(
            self.daily_publisher.publish_tcm_tech_focus,
            trigger=CronTrigger(hour=14, minute=0),
            id="tcm_tech_focus_job",
            name="ä¸­åŒ»ç§‘æŠ€ä¸“é¢˜å‘å¸ƒ",
            replace_existing=True,
            max_instances=1
        )
        
        # 16:00 - ç²¾é€‰è½¬å‘
        self.scheduler.add_job(
            self.daily_publisher.publish_curated_retweet,
            trigger=CronTrigger(hour=16, minute=0),
            id="curated_retweet_job",
            name="ç²¾é€‰è½¬å‘å‘å¸ƒ",
            replace_existing=True,
            max_instances=1
        )
        
        # 20:00 - æœ¬å‘¨å›é¡¾ï¼ˆä»…å‘¨æ—¥ï¼‰
        self.scheduler.add_job(
            self.daily_publisher.publish_weekly_recap,
            trigger=CronTrigger(hour=20, minute=0, day_of_week=6),  # å‘¨æ—¥
            id="weekly_recap_job",
            name="æœ¬å‘¨ç§‘æŠ€è¶‹åŠ¿å›é¡¾",
            replace_existing=True,
            max_instances=1
        )
        
        # === åŸæœ‰çš„åˆ†æä»»åŠ¡ï¼ˆä¿ç•™ä½†é™ä½é¢‘ç‡ï¼‰ ===
        
        # è¶‹åŠ¿åˆ†æä»»åŠ¡ - æ¯6å°æ—¶ï¼ˆé™ä½é¢‘ç‡ï¼‰
        self.scheduler.add_job(
            self.execute_trend_analysis_task,
            trigger=IntervalTrigger(hours=6),
            id="trend_analysis_job",
            name="æ·±åº¦è¶‹åŠ¿åˆ†æ",
            replace_existing=True,
            max_instances=1
        )
        
        # äº’åŠ¨æ£€æŸ¥ä»»åŠ¡ - æ¯8å°æ—¶
        self.scheduler.add_job(
            self.execute_engagement_check_task,
            trigger=IntervalTrigger(hours=8),
            id="engagement_check_job", 
            name="äº’åŠ¨ç›‘æ§ä¸å›åº”",
            replace_existing=True,
            max_instances=1
        )
        
        # æ•°æ®å¯è§†åŒ–ä»»åŠ¡ - æ¯12å°æ—¶
        self.scheduler.add_job(
            self.execute_data_visualization_task,
            trigger=IntervalTrigger(hours=12),
            id="data_visualization_job",
            name="ç§‘æŠ€æ•°æ®å¯è§†åŒ–åˆ†æ",
            replace_existing=True,
            max_instances=1
        )
        
        # å›¾ç‰‡æ¨æ–‡ä»»åŠ¡ - æ¯6å°æ—¶
        self.scheduler.add_job(
            self.execute_image_tweet_task,
            trigger=IntervalTrigger(hours=6),
            id="image_tweet_job",
            name="å›¾ç‰‡æ¨æ–‡è‡ªåŠ¨å‘å¸ƒ",
            replace_existing=True,
            max_instances=1
        )
    
    async def start(self):
        """å¯åŠ¨è°ƒåº¦å™¨"""
        try:
            self.logger.info("ğŸ”§ æ­£åœ¨å¯åŠ¨Manual Twitterè°ƒåº¦å™¨...")
            
            self.add_scheduled_jobs()
            self.scheduler.start()
            
            self.logger.info(f"âœ… è°ƒåº¦å™¨å·²å¯åŠ¨ï¼Œæ‰§è¡Œé—´éš”: {self.interval_hours}å°æ—¶")
            
            # åˆ—å‡ºä»»åŠ¡
            for job in self.scheduler.get_jobs():
                next_run = job.next_run_time.strftime("%Y-%m-%d %H:%M:%S") if job.next_run_time else "æœªçŸ¥"
                self.logger.info(f"  ğŸ“‹ {job.name} (ä¸‹æ¬¡æ‰§è¡Œ: {next_run})")
            
        except Exception as e:
            self.logger.error(f"âŒ è°ƒåº¦å™¨å¯åŠ¨å¤±è´¥: {str(e)}")
            raise
    
    async def stop(self):
        """åœæ­¢è°ƒåº¦å™¨"""
        try:
            self.scheduler.shutdown(wait=False)
            self.logger.info("ğŸ›‘ è°ƒåº¦å™¨å·²åœæ­¢")
        except Exception as e:
            self.logger.error(f"âŒ è°ƒåº¦å™¨åœæ­¢å¤±è´¥: {str(e)}")


async def main():
    """ä¸»å‡½æ•°"""
    load_dotenv()
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    required_vars = ["ANTHROPIC_API_KEY", "TAVILY_API_KEY"]
    missing_vars = [var for var in required_vars if not os.getenv(var)]
    
    if missing_vars:
        print(f"âŒ ç¼ºå°‘ç¯å¢ƒå˜é‡: {', '.join(missing_vars)}")
        return
    
    # åˆ›å»ºè°ƒåº¦å™¨
    scheduler = ManualTwitterScheduler(interval_hours=1)  # æµ‹è¯•æ—¶1å°æ—¶
    
    try:
        # å…ˆæ‰§è¡Œä¸€æ¬¡æµ‹è¯•
        print("ğŸ§ª æ‰§è¡Œå•æ¬¡æµ‹è¯•...")
        await scheduler.execute_trend_analysis_task()
        
        # å¯åŠ¨è°ƒåº¦å™¨
        await scheduler.start()
        
        # è¿è¡Œè°ƒåº¦å™¨
        print("ğŸ”„ è°ƒåº¦å™¨æ­£åœ¨è¿è¡Œ... æŒ‰ Ctrl+C åœæ­¢")
        try:
            while True:
                await asyncio.sleep(60)
        except KeyboardInterrupt:
            print("\nğŸ‘‹ æ”¶åˆ°åœæ­¢ä¿¡å·...")
        
    except Exception as e:
        print(f"âŒ ç¨‹åºå‡ºé”™: {str(e)}")
    finally:
        await scheduler.stop()


if __name__ == "__main__":
    asyncio.run(main())