#!/usr/bin/env python3
"""ä½¿ç”¨LangGraphå‘å¸ƒAIå¤´æ¡æ¨æ–‡"""

import asyncio
import sys
from pathlib import Path
from dotenv import load_dotenv

load_dotenv()

# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root / "src"))

from react_agent.context import Context
from react_agent.graph import graph
from react_agent.state import InputState
from langchain_core.messages import HumanMessage


async def publish_ai_tweet_via_graph():
    """é€šè¿‡LangGraphå‘å¸ƒAIå¤´æ¡æ¨æ–‡"""
    try:
        print("ğŸš€ å¼€å§‹ä½¿ç”¨LangGraphå‘å¸ƒAIå¤´æ¡æ¨æ–‡...")
        
        # ç”¨æˆ·æŒ‡å®šçš„æ¨æ–‡å†…å®¹
        tweet_content = """ğŸ“Š ä»Šæ—¥AIå¤´æ¡ #AIæ–°é—» #ç§‘æŠ€å‰æ²¿

1. OpenAIæ–°æ¨¡å‹çªç ´è¯­è¨€ç†è§£ç“¶é¢ˆ
2. è‡ªåŠ¨é©¾é©¶AIåœ¨å¤æ‚è·¯å†µæµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚
3. AIè¾…åŠ©ç™Œç—‡è¯Šæ–­å‡†ç¡®ç‡æå‡15%
4. ä¼¦ç†AI: æ–°æ¡†æ¶è§£å†³åè§é—®é¢˜
5. AIåˆ›ä½œéŸ³ä¹ç™»ä¸ŠBillboardæ¦œå•

ç‚¹å‡»æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯å›¾è¡¨ğŸ‘‡
æƒ³æ·±å…¥äº†è§£å“ªä¸ªè¯é¢˜ï¼Ÿ"""
        
        # ç”¨æˆ·æŒ‡å®šçš„å›¾ç‰‡è·¯å¾„
        image_path = "/Users/siying/git/project/twitter/images/chart_market_summary_20250818_215704_watermarked_twitter.jpg"
        
        print(f"ğŸ“ æ¨æ–‡å†…å®¹:\n{tweet_content}")
        print(f"ğŸ–¼ï¸ é…å›¾: {image_path}")
        
        # åˆ›å»ºè®©AI agentå‘å¸ƒæ¨æ–‡çš„æŒ‡ä»¤
        instruction = f"""è¯·å‘å¸ƒä»¥ä¸‹æ¨æ–‡åˆ°Twitterï¼Œå¹¶é™„ä¸ŠæŒ‡å®šçš„å›¾ç‰‡ï¼š

æ¨æ–‡å†…å®¹:
{tweet_content}

å›¾ç‰‡è·¯å¾„: {image_path}

è¯·ä½¿ç”¨post_tweetå·¥å…·å‘å¸ƒè¿™æ¡æ¨æ–‡ã€‚"""
        
        # åˆ›å»ºè¾“å…¥çŠ¶æ€
        input_state = InputState(
            messages=[HumanMessage(content=instruction)]
        )
        
        print(f"ğŸ“¤ AIæŒ‡ä»¤: {instruction[:100]}...")
        
        # åˆ›å»ºcontexté…ç½®
        context = Context()
        print(f"ğŸ”§ Contexté…ç½®: model={context.model}")
        
        print("\nğŸ¤– æ­£åœ¨é€šè¿‡AI agentå‘å¸ƒæ¨æ–‡...")
        
        # è°ƒç”¨graphè®©AI agentæ‰§è¡Œå‘å¸ƒ
        result = await graph.ainvoke(
            input_state,
            config={
                "recursion_limit": 10,
                "configurable": {
                    "model": context.model,
                    "system_prompt": context.system_prompt,
                    "max_search_results": context.max_search_results,
                    "twitter_user_id": context.twitter_user_id
                }
            }
        )
        
        print("âœ… AI agentå¤„ç†å®Œæˆ!")
        
        if result and result.get("messages"):
            last_message = result["messages"][-1]
            print(f"ğŸ¯ AIå“åº”: {last_message.content}")
            
            # æ£€æŸ¥æ˜¯å¦æˆåŠŸå‘å¸ƒ
            if "æˆåŠŸ" in last_message.content or "successfully" in last_message.content.lower():
                print("ğŸ‰ æ¨æ–‡å‘å¸ƒæˆåŠŸï¼")
                return True
            else:
                print("âš ï¸  æ¨æ–‡å‘å¸ƒçŠ¶æ€éœ€è¦ç¡®è®¤")
        
        return False
        
    except Exception as e:
        print(f"âŒ å‘å¸ƒå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    asyncio.run(publish_ai_tweet_via_graph())